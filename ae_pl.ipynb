{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of autoencoder (AE) with pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: 784 -> 64 -> 3 -> 64 -> 784\n",
    "encoder = nn.Sequential(nn.Linear(28 * 28, 64), \n",
    "                        nn.ReLU(), \n",
    "                        nn.Linear(64, 3))\n",
    "decoder = nn.Sequential(nn.Linear(3, 64), \n",
    "                        nn.ReLU(), \n",
    "                        nn.Linear(64, 28 * 28))\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        # Include extra logging here\n",
    "        self.log('train_loss', loss)\n",
    "        print(f'train_loss: {loss}')\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "ae = LitAutoEncoder(encoder, decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 50.4 K\n",
      "1 | decoder | Sequential | 51.2 K\n",
      "---------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "/home/augix/miniconda/envs/mamba/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e783b146dc4108a2dfd5764e52b777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.12982700765132904\n",
      "train_loss: 0.14043591916561127\n",
      "train_loss: 0.13210667669773102\n",
      "train_loss: 0.11799132823944092\n",
      "train_loss: 0.12972961366176605\n",
      "train_loss: 0.1236516609787941\n",
      "train_loss: 0.12556129693984985\n",
      "train_loss: 0.1233401745557785\n",
      "train_loss: 0.10441011190414429\n",
      "train_loss: 0.11241642385721207\n",
      "train_loss: 0.110621877014637\n",
      "train_loss: 0.10509290546178818\n",
      "train_loss: 0.10522322356700897\n",
      "train_loss: 0.09652478992938995\n",
      "train_loss: 0.09180828183889389\n",
      "train_loss: 0.10036342591047287\n",
      "train_loss: 0.08846341073513031\n",
      "train_loss: 0.09337251633405685\n",
      "train_loss: 0.0965307354927063\n",
      "train_loss: 0.0909583568572998\n",
      "train_loss: 0.09523572772741318\n",
      "train_loss: 0.09019909799098969\n",
      "train_loss: 0.08766265958547592\n",
      "train_loss: 0.08130418509244919\n",
      "train_loss: 0.08146239817142487\n",
      "train_loss: 0.07984609156847\n",
      "train_loss: 0.08516711741685867\n",
      "train_loss: 0.0824030190706253\n",
      "train_loss: 0.081952765583992\n",
      "train_loss: 0.0801665335893631\n",
      "train_loss: 0.07392263412475586\n",
      "train_loss: 0.07589466869831085\n",
      "train_loss: 0.06557458639144897\n",
      "train_loss: 0.07355799525976181\n",
      "train_loss: 0.07029975950717926\n",
      "train_loss: 0.0692698135972023\n",
      "train_loss: 0.07468414306640625\n",
      "train_loss: 0.06699186563491821\n",
      "train_loss: 0.07192279398441315\n",
      "train_loss: 0.07663650810718536\n",
      "train_loss: 0.07154271006584167\n",
      "train_loss: 0.07114122062921524\n",
      "train_loss: 0.06985970586538315\n",
      "train_loss: 0.06887918710708618\n",
      "train_loss: 0.06368609517812729\n",
      "train_loss: 0.06936578452587128\n",
      "train_loss: 0.064524807035923\n",
      "train_loss: 0.0645061582326889\n",
      "train_loss: 0.06408549845218658\n",
      "train_loss: 0.06646732240915298\n",
      "train_loss: 0.06501880288124084\n",
      "train_loss: 0.06470455229282379\n",
      "train_loss: 0.06518714129924774\n",
      "train_loss: 0.06110144406557083\n",
      "train_loss: 0.059283528476953506\n",
      "train_loss: 0.05927424505352974\n",
      "train_loss: 0.06384758651256561\n",
      "train_loss: 0.06518086791038513\n",
      "train_loss: 0.06442514806985855\n",
      "train_loss: 0.06301095336675644\n",
      "train_loss: 0.06708270311355591\n",
      "train_loss: 0.06897665560245514\n",
      "train_loss: 0.060707032680511475\n",
      "train_loss: 0.06788474321365356\n",
      "train_loss: 0.06790071725845337\n",
      "train_loss: 0.0645606741309166\n",
      "train_loss: 0.07045791298151016\n",
      "train_loss: 0.06078699976205826\n",
      "train_loss: 0.06475475430488586\n",
      "train_loss: 0.06338103115558624\n",
      "train_loss: 0.06575077027082443\n",
      "train_loss: 0.06175003573298454\n",
      "train_loss: 0.06491033732891083\n",
      "train_loss: 0.06272689253091812\n",
      "train_loss: 0.06414948403835297\n",
      "train_loss: 0.06268765032291412\n",
      "train_loss: 0.06153363361954689\n",
      "train_loss: 0.06342528015375137\n",
      "train_loss: 0.06427434086799622\n",
      "train_loss: 0.06031949073076248\n",
      "train_loss: 0.060572728514671326\n",
      "train_loss: 0.05930519104003906\n",
      "train_loss: 0.06277760863304138\n",
      "train_loss: 0.057564783841371536\n",
      "train_loss: 0.05901190638542175\n",
      "train_loss: 0.060457952320575714\n",
      "train_loss: 0.062229935079813004\n",
      "train_loss: 0.06028511002659798\n",
      "train_loss: 0.0647488608956337\n",
      "train_loss: 0.058718252927064896\n",
      "train_loss: 0.06035784259438515\n",
      "train_loss: 0.06101265177130699\n",
      "train_loss: 0.06150916591286659\n",
      "train_loss: 0.056628964841365814\n",
      "train_loss: 0.06081949919462204\n",
      "train_loss: 0.05926598235964775\n",
      "train_loss: 0.05826353281736374\n",
      "train_loss: 0.05813680216670036\n",
      "train_loss: 0.06270965933799744\n",
      "train_loss: 0.06121045723557472\n",
      "train_loss: 0.05887283384799957\n",
      "train_loss: 0.05999797582626343\n",
      "train_loss: 0.05623489245772362\n",
      "train_loss: 0.057922717183828354\n",
      "train_loss: 0.05519256740808487\n",
      "train_loss: 0.05668488144874573\n",
      "train_loss: 0.06161656975746155\n",
      "train_loss: 0.059709809720516205\n",
      "train_loss: 0.05756756663322449\n",
      "train_loss: 0.05357249826192856\n",
      "train_loss: 0.06395190954208374\n",
      "train_loss: 0.05859123915433884\n",
      "train_loss: 0.056288376450538635\n",
      "train_loss: 0.053567927330732346\n",
      "train_loss: 0.057758133858442307\n",
      "train_loss: 0.06204219162464142\n",
      "train_loss: 0.05541118606925011\n",
      "train_loss: 0.05566161870956421\n",
      "train_loss: 0.05504295229911804\n",
      "train_loss: 0.05662533640861511\n",
      "train_loss: 0.05557332560420036\n",
      "train_loss: 0.054561518132686615\n",
      "train_loss: 0.05921564996242523\n",
      "train_loss: 0.0520983524620533\n",
      "train_loss: 0.050407908856868744\n",
      "train_loss: 0.05568482726812363\n",
      "train_loss: 0.05433107912540436\n",
      "train_loss: 0.05100943520665169\n",
      "train_loss: 0.05868609994649887\n",
      "train_loss: 0.05758786201477051\n",
      "train_loss: 0.05307280644774437\n",
      "train_loss: 0.06035134568810463\n",
      "train_loss: 0.05700715631246567\n",
      "train_loss: 0.05303434655070305\n",
      "train_loss: 0.056984398514032364\n",
      "train_loss: 0.056482668966054916\n",
      "train_loss: 0.05648111552000046\n",
      "train_loss: 0.05602163076400757\n",
      "train_loss: 0.05531719699501991\n",
      "train_loss: 0.05672907084226608\n",
      "train_loss: 0.05324659124016762\n",
      "train_loss: 0.05564550682902336\n",
      "train_loss: 0.054596442729234695\n",
      "train_loss: 0.05459119752049446\n",
      "train_loss: 0.05915900692343712\n",
      "train_loss: 0.05635682865977287\n",
      "train_loss: 0.053908515721559525\n",
      "train_loss: 0.053021788597106934\n",
      "train_loss: 0.05288118124008179\n",
      "train_loss: 0.05503876879811287\n",
      "train_loss: 0.055871348828077316\n",
      "train_loss: 0.05135064944624901\n",
      "train_loss: 0.05676244571805\n",
      "train_loss: 0.0561259463429451\n",
      "train_loss: 0.05342383682727814\n",
      "train_loss: 0.054345279932022095\n",
      "train_loss: 0.05282435566186905\n",
      "train_loss: 0.05015804246068001\n",
      "train_loss: 0.052787989377975464\n",
      "train_loss: 0.05394601821899414\n",
      "train_loss: 0.05186226963996887\n",
      "train_loss: 0.050506241619586945\n",
      "train_loss: 0.04486512020230293\n",
      "train_loss: 0.04957206919789314\n",
      "train_loss: 0.05875728279352188\n",
      "train_loss: 0.04505298659205437\n",
      "train_loss: 0.055787794291973114\n",
      "train_loss: 0.05570581927895546\n",
      "train_loss: 0.05505460500717163\n",
      "train_loss: 0.056201688945293427\n",
      "train_loss: 0.05613643303513527\n",
      "train_loss: 0.05493602901697159\n",
      "train_loss: 0.05445617809891701\n",
      "train_loss: 0.04879026859998703\n",
      "train_loss: 0.0540303960442543\n",
      "train_loss: 0.05156291648745537\n",
      "train_loss: 0.053228721022605896\n",
      "train_loss: 0.05315430834889412\n",
      "train_loss: 0.04672854021191597\n",
      "train_loss: 0.05141797661781311\n",
      "train_loss: 0.054830681532621384\n",
      "train_loss: 0.050409987568855286\n",
      "train_loss: 0.04897485300898552\n",
      "train_loss: 0.05395786836743355\n",
      "train_loss: 0.05169415846467018\n",
      "train_loss: 0.056659214198589325\n",
      "train_loss: 0.05311572551727295\n",
      "train_loss: 0.05566948652267456\n",
      "train_loss: 0.05073803663253784\n",
      "train_loss: 0.049566831439733505\n",
      "train_loss: 0.050643257796764374\n",
      "train_loss: 0.04921811819076538\n",
      "train_loss: 0.054305464029312134\n",
      "train_loss: 0.057289641350507736\n",
      "train_loss: 0.04673664644360542\n",
      "train_loss: 0.05141117423772812\n",
      "train_loss: 0.060029320418834686\n",
      "train_loss: 0.05460949242115021\n",
      "train_loss: 0.05365382879972458\n",
      "train_loss: 0.05193615332245827\n",
      "train_loss: 0.053255558013916016\n",
      "train_loss: 0.05461177974939346\n",
      "train_loss: 0.05092097818851471\n",
      "train_loss: 0.05018541216850281\n",
      "train_loss: 0.052987027913331985\n",
      "train_loss: 0.051854055374860764\n",
      "train_loss: 0.056279104202985764\n",
      "train_loss: 0.048081863671541214\n",
      "train_loss: 0.056559979915618896\n",
      "train_loss: 0.05229656770825386\n",
      "train_loss: 0.049338243901729584\n",
      "train_loss: 0.047721974551677704\n",
      "train_loss: 0.053566016256809235\n",
      "train_loss: 0.05450236424803734\n",
      "train_loss: 0.05415574833750725\n",
      "train_loss: 0.05088432505726814\n",
      "train_loss: 0.04522641375660896\n",
      "train_loss: 0.05178359895944595\n",
      "train_loss: 0.04590233787894249\n",
      "train_loss: 0.055800311267375946\n",
      "train_loss: 0.047235969454050064\n",
      "train_loss: 0.0515361987054348\n",
      "train_loss: 0.050775181502103806\n",
      "train_loss: 0.0522773414850235\n",
      "train_loss: 0.05223526060581207\n",
      "train_loss: 0.05012277513742447\n",
      "train_loss: 0.05507640168070793\n",
      "train_loss: 0.05166507139801979\n",
      "train_loss: 0.050905946642160416\n",
      "train_loss: 0.05589599534869194\n",
      "train_loss: 0.053588010370731354\n",
      "train_loss: 0.05079023167490959\n",
      "train_loss: 0.0530230738222599\n",
      "train_loss: 0.05033550411462784\n",
      "train_loss: 0.05218421667814255\n",
      "train_loss: 0.04967504367232323\n",
      "train_loss: 0.049885980784893036\n",
      "train_loss: 0.05415848270058632\n",
      "train_loss: 0.05121450871229172\n",
      "train_loss: 0.04771644249558449\n",
      "train_loss: 0.049224935472011566\n",
      "train_loss: 0.049908947199583054\n",
      "train_loss: 0.04669418931007385\n",
      "train_loss: 0.05102074146270752\n",
      "train_loss: 0.053230732679367065\n",
      "train_loss: 0.04956255853176117\n",
      "train_loss: 0.045743703842163086\n",
      "train_loss: 0.04891073331236839\n",
      "train_loss: 0.04873482137918472\n",
      "train_loss: 0.04949177801609039\n",
      "train_loss: 0.05733703076839447\n",
      "train_loss: 0.05570915341377258\n",
      "train_loss: 0.04679829999804497\n",
      "train_loss: 0.04878217354416847\n",
      "train_loss: 0.044756509363651276\n",
      "train_loss: 0.05342104285955429\n",
      "train_loss: 0.052046775817871094\n",
      "train_loss: 0.05429254099726677\n",
      "train_loss: 0.04906317964196205\n",
      "train_loss: 0.0453806072473526\n",
      "train_loss: 0.053123313933610916\n",
      "train_loss: 0.047781310975551605\n",
      "train_loss: 0.0501963347196579\n",
      "train_loss: 0.04864773526787758\n",
      "train_loss: 0.051830440759658813\n",
      "train_loss: 0.050506435334682465\n",
      "train_loss: 0.04859761521220207\n",
      "train_loss: 0.050479479134082794\n",
      "train_loss: 0.0520019605755806\n",
      "train_loss: 0.046763401478528976\n",
      "train_loss: 0.05158394202589989\n",
      "train_loss: 0.04906012862920761\n",
      "train_loss: 0.04999418556690216\n",
      "train_loss: 0.05392327904701233\n",
      "train_loss: 0.057031773030757904\n",
      "train_loss: 0.05344733968377113\n",
      "train_loss: 0.04971957579255104\n",
      "train_loss: 0.048941247165203094\n",
      "train_loss: 0.05086490139365196\n",
      "train_loss: 0.04573825001716614\n",
      "train_loss: 0.048387739807367325\n",
      "train_loss: 0.04619941860437393\n",
      "train_loss: 0.050795745104551315\n",
      "train_loss: 0.05014513432979584\n",
      "train_loss: 0.050673309713602066\n",
      "train_loss: 0.04950390011072159\n",
      "train_loss: 0.04456866532564163\n",
      "train_loss: 0.05291743576526642\n",
      "train_loss: 0.04961476847529411\n",
      "train_loss: 0.0539650060236454\n",
      "train_loss: 0.046155501157045364\n",
      "train_loss: 0.05047011375427246\n",
      "train_loss: 0.04615823179483414\n",
      "train_loss: 0.053079381585121155\n",
      "train_loss: 0.04741629585623741\n",
      "train_loss: 0.05126659572124481\n",
      "train_loss: 0.04989754408597946\n",
      "train_loss: 0.04981796070933342\n",
      "train_loss: 0.048945408314466476\n",
      "train_loss: 0.04616820812225342\n",
      "train_loss: 0.04533999040722847\n",
      "train_loss: 0.04897575452923775\n",
      "train_loss: 0.050979647785425186\n",
      "train_loss: 0.04969983175396919\n",
      "train_loss: 0.049256522208452225\n",
      "train_loss: 0.04929061233997345\n",
      "train_loss: 0.04776211082935333\n",
      "train_loss: 0.04707661271095276\n",
      "train_loss: 0.04844865947961807\n",
      "train_loss: 0.04946552962064743\n",
      "train_loss: 0.04858236387372017\n",
      "train_loss: 0.046408072113990784\n",
      "train_loss: 0.045859042555093765\n",
      "train_loss: 0.046569161117076874\n",
      "train_loss: 0.05404410883784294\n",
      "train_loss: 0.052584175020456314\n",
      "train_loss: 0.047893669456243515\n",
      "train_loss: 0.04942423477768898\n",
      "train_loss: 0.045674946159124374\n",
      "train_loss: 0.04811493307352066\n",
      "train_loss: 0.048880431801080704\n",
      "train_loss: 0.04940081387758255\n",
      "train_loss: 0.04957657307386398\n",
      "train_loss: 0.0502861812710762\n",
      "train_loss: 0.04579814523458481\n",
      "train_loss: 0.05138230696320534\n",
      "train_loss: 0.05246767774224281\n",
      "train_loss: 0.05370438098907471\n",
      "train_loss: 0.04314044862985611\n",
      "train_loss: 0.05131850764155388\n",
      "train_loss: 0.0447353832423687\n",
      "train_loss: 0.04277392849326134\n",
      "train_loss: 0.04413416236639023\n",
      "train_loss: 0.05025934427976608\n",
      "train_loss: 0.05092454329133034\n",
      "train_loss: 0.050093211233615875\n",
      "train_loss: 0.04372643306851387\n",
      "train_loss: 0.04951782152056694\n",
      "train_loss: 0.05099381133913994\n",
      "train_loss: 0.0506424643099308\n",
      "train_loss: 0.04524444788694382\n",
      "train_loss: 0.05022988095879555\n",
      "train_loss: 0.04738731309771538\n",
      "train_loss: 0.051939234137535095\n",
      "train_loss: 0.04567714035511017\n",
      "train_loss: 0.04594556614756584\n",
      "train_loss: 0.05002971366047859\n",
      "train_loss: 0.04358982294797897\n",
      "train_loss: 0.049691151827573776\n",
      "train_loss: 0.049690425395965576\n",
      "train_loss: 0.05265374854207039\n",
      "train_loss: 0.047518540173769\n",
      "train_loss: 0.04753200709819794\n",
      "train_loss: 0.047559693455696106\n",
      "train_loss: 0.047065772116184235\n",
      "train_loss: 0.04249578341841698\n",
      "train_loss: 0.049118127673864365\n",
      "train_loss: 0.048535753041505814\n",
      "train_loss: 0.04684564843773842\n",
      "train_loss: 0.0509432852268219\n",
      "train_loss: 0.04641476273536682\n",
      "train_loss: 0.04407408833503723\n",
      "train_loss: 0.04947388917207718\n",
      "train_loss: 0.0460687056183815\n",
      "train_loss: 0.04662742838263512\n",
      "train_loss: 0.04817158728837967\n",
      "train_loss: 0.04427267611026764\n",
      "train_loss: 0.045816823840141296\n",
      "train_loss: 0.047281574457883835\n",
      "train_loss: 0.04726601019501686\n",
      "train_loss: 0.05192602798342705\n",
      "train_loss: 0.047305457293987274\n",
      "train_loss: 0.048042815178632736\n",
      "train_loss: 0.04501071572303772\n",
      "train_loss: 0.04653032869100571\n",
      "train_loss: 0.04619849845767021\n",
      "train_loss: 0.052651453763246536\n",
      "train_loss: 0.04804998263716698\n",
      "train_loss: 0.0486859492957592\n",
      "train_loss: 0.047342684119939804\n",
      "train_loss: 0.052082378417253494\n",
      "train_loss: 0.049958549439907074\n",
      "train_loss: 0.047049399465322495\n",
      "train_loss: 0.05228198319673538\n",
      "train_loss: 0.04842950403690338\n",
      "train_loss: 0.04279029369354248\n",
      "train_loss: 0.0443141832947731\n",
      "train_loss: 0.045286498963832855\n",
      "train_loss: 0.050078995525836945\n",
      "train_loss: 0.0463855005800724\n",
      "train_loss: 0.049203336238861084\n",
      "train_loss: 0.0454665869474411\n",
      "train_loss: 0.0455048605799675\n",
      "train_loss: 0.04594030976295471\n",
      "train_loss: 0.04939710348844528\n",
      "train_loss: 0.04889415204524994\n",
      "train_loss: 0.050863076001405716\n",
      "train_loss: 0.04799795523285866\n",
      "train_loss: 0.05031147226691246\n",
      "train_loss: 0.0492265447974205\n",
      "train_loss: 0.047620151191949844\n",
      "train_loss: 0.045982856303453445\n",
      "train_loss: 0.0475456565618515\n",
      "train_loss: 0.050265368074178696\n",
      "train_loss: 0.048274245113134384\n",
      "train_loss: 0.05068671703338623\n",
      "train_loss: 0.050607841461896896\n",
      "train_loss: 0.04977288469672203\n",
      "train_loss: 0.05001845583319664\n",
      "train_loss: 0.05374041199684143\n",
      "train_loss: 0.046788182109594345\n",
      "train_loss: 0.04818233102560043\n",
      "train_loss: 0.045920126140117645\n",
      "train_loss: 0.04959515854716301\n",
      "train_loss: 0.04847663640975952\n",
      "train_loss: 0.043557699769735336\n",
      "train_loss: 0.051942192018032074\n",
      "train_loss: 0.04653530567884445\n",
      "train_loss: 0.04279263690114021\n",
      "train_loss: 0.053097471594810486\n",
      "train_loss: 0.0415349081158638\n",
      "train_loss: 0.05137300491333008\n",
      "train_loss: 0.04354199022054672\n",
      "train_loss: 0.046225789934396744\n",
      "train_loss: 0.0458231046795845\n",
      "train_loss: 0.04532754421234131\n",
      "train_loss: 0.04339258000254631\n",
      "train_loss: 0.04080837219953537\n",
      "train_loss: 0.0455271452665329\n",
      "train_loss: 0.044979240745306015\n",
      "train_loss: 0.04841117188334465\n",
      "train_loss: 0.049114055931568146\n",
      "train_loss: 0.045230913907289505\n",
      "train_loss: 0.04580027610063553\n",
      "train_loss: 0.04706943780183792\n",
      "train_loss: 0.04968554899096489\n",
      "train_loss: 0.04919236898422241\n",
      "train_loss: 0.04523872211575508\n",
      "train_loss: 0.03873702883720398\n",
      "train_loss: 0.04492637887597084\n",
      "train_loss: 0.04662839695811272\n",
      "train_loss: 0.047623977065086365\n",
      "train_loss: 0.04765216261148453\n",
      "train_loss: 0.04903972148895264\n",
      "train_loss: 0.047985319048166275\n",
      "train_loss: 0.05129598081111908\n",
      "train_loss: 0.05453948304057121\n",
      "train_loss: 0.05095094442367554\n",
      "train_loss: 0.04809493198990822\n",
      "train_loss: 0.04357977211475372\n",
      "train_loss: 0.054339561611413956\n",
      "train_loss: 0.0499112531542778\n",
      "train_loss: 0.0472768172621727\n",
      "train_loss: 0.048132769763469696\n",
      "train_loss: 0.050557155162096024\n",
      "train_loss: 0.045535244047641754\n",
      "train_loss: 0.0499790720641613\n",
      "train_loss: 0.04945361241698265\n",
      "train_loss: 0.05177735164761543\n",
      "train_loss: 0.04931139945983887\n",
      "train_loss: 0.04315238073468208\n",
      "train_loss: 0.04577762261033058\n",
      "train_loss: 0.04648170247673988\n",
      "train_loss: 0.04497797414660454\n",
      "train_loss: 0.04688725993037224\n",
      "train_loss: 0.04860391467809677\n",
      "train_loss: 0.0476539172232151\n",
      "train_loss: 0.04638109356164932\n",
      "train_loss: 0.04590088874101639\n",
      "train_loss: 0.041853129863739014\n",
      "train_loss: 0.04896588250994682\n",
      "train_loss: 0.04689529910683632\n",
      "train_loss: 0.04507381096482277\n",
      "train_loss: 0.04364381730556488\n",
      "train_loss: 0.04332498088479042\n",
      "train_loss: 0.043658334761857986\n",
      "train_loss: 0.044254254549741745\n",
      "train_loss: 0.0437852218747139\n",
      "train_loss: 0.05284741893410683\n",
      "train_loss: 0.047809939831495285\n",
      "train_loss: 0.045536525547504425\n",
      "train_loss: 0.0409734770655632\n",
      "train_loss: 0.04462103545665741\n",
      "train_loss: 0.05164165422320366\n",
      "train_loss: 0.05122673138976097\n",
      "train_loss: 0.05304824933409691\n",
      "train_loss: 0.04369138926267624\n",
      "train_loss: 0.04691203683614731\n",
      "train_loss: 0.046213824301958084\n",
      "train_loss: 0.04970671236515045\n",
      "train_loss: 0.04904097691178322\n",
      "train_loss: 0.04624827951192856\n",
      "train_loss: 0.0397893562912941\n",
      "train_loss: 0.04729582741856575\n",
      "train_loss: 0.047392338514328\n",
      "train_loss: 0.04716552793979645\n",
      "train_loss: 0.04887104779481888\n",
      "train_loss: 0.04067674279212952\n",
      "train_loss: 0.04660240560770035\n",
      "train_loss: 0.04339032247662544\n",
      "train_loss: 0.04228870943188667\n",
      "train_loss: 0.050375841557979584\n",
      "train_loss: 0.04952448606491089\n",
      "train_loss: 0.042592912912368774\n",
      "train_loss: 0.0517730787396431\n",
      "train_loss: 0.04645789414644241\n",
      "train_loss: 0.04341362044215202\n",
      "train_loss: 0.04419522359967232\n",
      "train_loss: 0.046686891466379166\n",
      "train_loss: 0.03806616738438606\n",
      "train_loss: 0.04945758730173111\n",
      "train_loss: 0.047450754791498184\n",
      "train_loss: 0.04453710466623306\n",
      "train_loss: 0.04973556473851204\n",
      "train_loss: 0.045015741139650345\n",
      "train_loss: 0.04150645434856415\n",
      "train_loss: 0.05089228227734566\n",
      "train_loss: 0.05135287344455719\n",
      "train_loss: 0.04849798232316971\n",
      "train_loss: 0.04763935133814812\n",
      "train_loss: 0.04623068496584892\n",
      "train_loss: 0.04633926600217819\n",
      "train_loss: 0.04596017301082611\n",
      "train_loss: 0.04926036298274994\n",
      "train_loss: 0.05083995684981346\n",
      "train_loss: 0.04931965097784996\n",
      "train_loss: 0.05348667874932289\n",
      "train_loss: 0.043326061218976974\n",
      "train_loss: 0.04879426211118698\n",
      "train_loss: 0.04691736772656441\n",
      "train_loss: 0.043687332421541214\n",
      "train_loss: 0.045674197375774384\n",
      "train_loss: 0.042415209114551544\n",
      "train_loss: 0.04570211470127106\n",
      "train_loss: 0.039917852729558945\n",
      "train_loss: 0.055803559720516205\n",
      "train_loss: 0.04630596563220024\n",
      "train_loss: 0.04903488978743553\n",
      "train_loss: 0.044669196009635925\n",
      "train_loss: 0.04970952868461609\n",
      "train_loss: 0.047323502600193024\n",
      "train_loss: 0.04843800142407417\n",
      "train_loss: 0.041777949780225754\n",
      "train_loss: 0.047264836728572845\n",
      "train_loss: 0.04499006271362305\n",
      "train_loss: 0.04642647132277489\n",
      "train_loss: 0.04171193391084671\n",
      "train_loss: 0.04165641590952873\n",
      "train_loss: 0.05052011087536812\n",
      "train_loss: 0.04821811243891716\n",
      "train_loss: 0.0427200049161911\n",
      "train_loss: 0.045133668929338455\n",
      "train_loss: 0.04743706434965134\n",
      "train_loss: 0.046334777027368546\n",
      "train_loss: 0.048533789813518524\n",
      "train_loss: 0.04805807024240494\n",
      "train_loss: 0.04291532561182976\n",
      "train_loss: 0.04351998120546341\n",
      "train_loss: 0.04464365541934967\n",
      "train_loss: 0.043478041887283325\n",
      "train_loss: 0.046179868280887604\n",
      "train_loss: 0.046422213315963745\n",
      "train_loss: 0.04070234298706055\n",
      "train_loss: 0.04543287679553032\n",
      "train_loss: 0.047403860837221146\n",
      "train_loss: 0.0420670211315155\n",
      "train_loss: 0.05304275080561638\n",
      "train_loss: 0.0489216148853302\n",
      "train_loss: 0.046756189316511154\n",
      "train_loss: 0.04221819341182709\n",
      "train_loss: 0.0427589938044548\n",
      "train_loss: 0.047934286296367645\n",
      "train_loss: 0.04912954941391945\n",
      "train_loss: 0.049587950110435486\n",
      "train_loss: 0.05052226781845093\n",
      "train_loss: 0.05133664235472679\n",
      "train_loss: 0.048767779022455215\n",
      "train_loss: 0.04390376806259155\n",
      "train_loss: 0.04873201623558998\n",
      "train_loss: 0.042920976877212524\n",
      "train_loss: 0.05030874162912369\n",
      "train_loss: 0.04538004472851753\n",
      "train_loss: 0.04532372206449509\n",
      "train_loss: 0.0417964905500412\n",
      "train_loss: 0.045308683067560196\n",
      "train_loss: 0.045948464423418045\n",
      "train_loss: 0.045637547969818115\n",
      "train_loss: 0.04215475916862488\n",
      "train_loss: 0.04331525042653084\n",
      "train_loss: 0.047097038477659225\n",
      "train_loss: 0.04228819161653519\n",
      "train_loss: 0.045642271637916565\n",
      "train_loss: 0.043628595769405365\n",
      "train_loss: 0.045765336602926254\n",
      "train_loss: 0.04825398698449135\n",
      "train_loss: 0.047079045325517654\n",
      "train_loss: 0.04386769235134125\n",
      "train_loss: 0.04557369276881218\n",
      "train_loss: 0.044420816004276276\n",
      "train_loss: 0.04417949542403221\n",
      "train_loss: 0.05023948848247528\n",
      "train_loss: 0.04382181167602539\n",
      "train_loss: 0.04998641088604927\n",
      "train_loss: 0.050932299345731735\n",
      "train_loss: 0.04572372883558273\n",
      "train_loss: 0.044828757643699646\n",
      "train_loss: 0.049534544348716736\n",
      "train_loss: 0.048140786588191986\n",
      "train_loss: 0.04286878928542137\n",
      "train_loss: 0.04641551151871681\n",
      "train_loss: 0.04630173370242119\n",
      "train_loss: 0.04464241862297058\n",
      "train_loss: 0.04523266851902008\n",
      "train_loss: 0.04428458958864212\n",
      "train_loss: 0.03902529925107956\n",
      "train_loss: 0.044185589998960495\n",
      "train_loss: 0.04715503379702568\n",
      "train_loss: 0.04676531255245209\n",
      "train_loss: 0.0471377857029438\n",
      "train_loss: 0.042900532484054565\n",
      "train_loss: 0.04771208018064499\n",
      "train_loss: 0.0400785431265831\n",
      "train_loss: 0.051435455679893494\n",
      "train_loss: 0.04325355589389801\n",
      "train_loss: 0.047736428678035736\n",
      "train_loss: 0.042627692222595215\n",
      "train_loss: 0.042379822582006454\n",
      "train_loss: 0.04691843315958977\n",
      "train_loss: 0.04536597803235054\n",
      "train_loss: 0.04540145397186279\n",
      "train_loss: 0.04549550265073776\n",
      "train_loss: 0.04674438387155533\n",
      "train_loss: 0.04616276174783707\n",
      "train_loss: 0.04618312790989876\n",
      "train_loss: 0.044569261372089386\n",
      "train_loss: 0.04881171137094498\n",
      "train_loss: 0.044756319373846054\n",
      "train_loss: 0.049386121332645416\n",
      "train_loss: 0.049857888370752335\n",
      "train_loss: 0.05201995372772217\n",
      "train_loss: 0.046264730393886566\n",
      "train_loss: 0.04155907407402992\n",
      "train_loss: 0.043441709131002426\n",
      "train_loss: 0.04644719883799553\n",
      "train_loss: 0.048790715634822845\n",
      "train_loss: 0.044306013733148575\n",
      "train_loss: 0.04846428707242012\n",
      "train_loss: 0.048442572355270386\n",
      "train_loss: 0.05230109393596649\n",
      "train_loss: 0.041031137108802795\n",
      "train_loss: 0.046518053859472275\n",
      "train_loss: 0.04616442322731018\n",
      "train_loss: 0.045458246022462845\n",
      "train_loss: 0.045826930552721024\n",
      "train_loss: 0.04453286901116371\n",
      "train_loss: 0.04867088794708252\n",
      "train_loss: 0.04456626623868942\n",
      "train_loss: 0.0414530485868454\n",
      "train_loss: 0.04213320463895798\n",
      "train_loss: 0.04024187847971916\n",
      "train_loss: 0.04195874556899071\n",
      "train_loss: 0.0493735633790493\n",
      "train_loss: 0.05140247568488121\n",
      "train_loss: 0.04740072786808014\n",
      "train_loss: 0.04373200982809067\n",
      "train_loss: 0.04506601393222809\n",
      "train_loss: 0.040748585015535355\n",
      "train_loss: 0.05003960058093071\n",
      "train_loss: 0.046558983623981476\n",
      "train_loss: 0.05066562071442604\n",
      "train_loss: 0.043012842535972595\n",
      "train_loss: 0.047768671065568924\n",
      "train_loss: 0.043357789516448975\n",
      "train_loss: 0.04140932485461235\n",
      "train_loss: 0.03870067000389099\n",
      "train_loss: 0.043901436030864716\n",
      "train_loss: 0.048139262944459915\n",
      "train_loss: 0.04460512846708298\n",
      "train_loss: 0.04577554389834404\n",
      "train_loss: 0.04558359831571579\n",
      "train_loss: 0.03958829119801521\n",
      "train_loss: 0.04327894747257233\n",
      "train_loss: 0.04485493525862694\n",
      "train_loss: 0.048195671290159225\n",
      "train_loss: 0.04199744015932083\n",
      "train_loss: 0.04355452582240105\n",
      "train_loss: 0.04227875545620918\n",
      "train_loss: 0.04344969615340233\n",
      "train_loss: 0.043105315417051315\n",
      "train_loss: 0.045868754386901855\n",
      "train_loss: 0.04201357439160347\n",
      "train_loss: 0.0419652946293354\n",
      "train_loss: 0.045226555317640305\n",
      "train_loss: 0.04727613553404808\n",
      "train_loss: 0.04119238629937172\n",
      "train_loss: 0.04450385645031929\n",
      "train_loss: 0.050701435655355453\n",
      "train_loss: 0.043989069759845734\n",
      "train_loss: 0.050464335829019547\n",
      "train_loss: 0.0438866950571537\n",
      "train_loss: 0.04667583853006363\n",
      "train_loss: 0.04351203143596649\n",
      "train_loss: 0.04594001546502113\n",
      "train_loss: 0.044462572783231735\n",
      "train_loss: 0.04812399297952652\n",
      "train_loss: 0.05004667490720749\n",
      "train_loss: 0.043414536863565445\n",
      "train_loss: 0.04706483706831932\n",
      "train_loss: 0.03966786339879036\n",
      "train_loss: 0.046441514045000076\n",
      "train_loss: 0.04802171513438225\n",
      "train_loss: 0.03786539286375046\n",
      "train_loss: 0.042925238609313965\n",
      "train_loss: 0.05207372084259987\n",
      "train_loss: 0.043005723506212234\n",
      "train_loss: 0.04224320128560066\n",
      "train_loss: 0.038384173065423965\n",
      "train_loss: 0.05023786053061485\n",
      "train_loss: 0.049550436437129974\n",
      "train_loss: 0.04737227037549019\n",
      "train_loss: 0.045276347547769547\n",
      "train_loss: 0.04767753183841705\n",
      "train_loss: 0.04323158413171768\n",
      "train_loss: 0.046174321323633194\n",
      "train_loss: 0.04253733903169632\n",
      "train_loss: 0.048391472548246384\n",
      "train_loss: 0.047549791634082794\n",
      "train_loss: 0.04764720797538757\n",
      "train_loss: 0.04110616818070412\n",
      "train_loss: 0.043211761862039566\n",
      "train_loss: 0.044102877378463745\n",
      "train_loss: 0.0445091538131237\n",
      "train_loss: 0.04789493978023529\n",
      "train_loss: 0.0451386496424675\n",
      "train_loss: 0.046665698289871216\n",
      "train_loss: 0.045122526586055756\n",
      "train_loss: 0.04672520235180855\n",
      "train_loss: 0.0460967943072319\n",
      "train_loss: 0.04559160768985748\n",
      "train_loss: 0.04056528955698013\n",
      "train_loss: 0.042494501918554306\n",
      "train_loss: 0.0435844250023365\n",
      "train_loss: 0.045440372079610825\n",
      "train_loss: 0.04169120639562607\n",
      "train_loss: 0.04486361891031265\n",
      "train_loss: 0.044320233166217804\n",
      "train_loss: 0.04452173784375191\n",
      "train_loss: 0.04532347247004509\n",
      "train_loss: 0.041109710931777954\n",
      "train_loss: 0.04302277788519859\n",
      "train_loss: 0.04540403559803963\n",
      "train_loss: 0.04444218426942825\n",
      "train_loss: 0.04248072952032089\n",
      "train_loss: 0.04341975972056389\n",
      "train_loss: 0.04468953609466553\n",
      "train_loss: 0.04619280621409416\n",
      "train_loss: 0.040394194424152374\n",
      "train_loss: 0.04758094251155853\n",
      "train_loss: 0.04190244525671005\n",
      "train_loss: 0.045392297208309174\n",
      "train_loss: 0.04246474802494049\n",
      "train_loss: 0.04617677256464958\n",
      "train_loss: 0.03672610595822334\n",
      "train_loss: 0.0347391813993454\n",
      "train_loss: 0.043782789260149\n",
      "train_loss: 0.051697585731744766\n",
      "train_loss: 0.045636508613824844\n",
      "train_loss: 0.04358414560556412\n",
      "train_loss: 0.04709039255976677\n",
      "train_loss: 0.0425676591694355\n",
      "train_loss: 0.04368118196725845\n",
      "train_loss: 0.04580264165997505\n",
      "train_loss: 0.04237650707364082\n",
      "train_loss: 0.04623003304004669\n",
      "train_loss: 0.04365186765789986\n",
      "train_loss: 0.04049760848283768\n",
      "train_loss: 0.04413606598973274\n",
      "train_loss: 0.043042298406362534\n",
      "train_loss: 0.03801380842924118\n",
      "train_loss: 0.04815969243645668\n",
      "train_loss: 0.039648815989494324\n",
      "train_loss: 0.04703401029109955\n",
      "train_loss: 0.04637667536735535\n",
      "train_loss: 0.04715953767299652\n",
      "train_loss: 0.045521870255470276\n",
      "train_loss: 0.03598636016249657\n",
      "train_loss: 0.04430064186453819\n",
      "train_loss: 0.04858751222491264\n",
      "train_loss: 0.044148437678813934\n",
      "train_loss: 0.03928902745246887\n",
      "train_loss: 0.045556649565696716\n",
      "train_loss: 0.04729074239730835\n",
      "train_loss: 0.04382491856813431\n",
      "train_loss: 0.0433129146695137\n",
      "train_loss: 0.04359522461891174\n",
      "train_loss: 0.043658509850502014\n",
      "train_loss: 0.04441387578845024\n",
      "train_loss: 0.04726829379796982\n",
      "train_loss: 0.04202990606427193\n",
      "train_loss: 0.04292488098144531\n",
      "train_loss: 0.04717493802309036\n",
      "train_loss: 0.0415620319545269\n",
      "train_loss: 0.04683523625135422\n",
      "train_loss: 0.04181526228785515\n",
      "train_loss: 0.04732459783554077\n",
      "train_loss: 0.043206725269556046\n",
      "train_loss: 0.04334094375371933\n",
      "train_loss: 0.04755149409174919\n",
      "train_loss: 0.044854503124952316\n",
      "train_loss: 0.0457971915602684\n",
      "train_loss: 0.04668685793876648\n",
      "train_loss: 0.04423677548766136\n",
      "train_loss: 0.038794443011283875\n",
      "train_loss: 0.04451122134923935\n",
      "train_loss: 0.042928677052259445\n",
      "train_loss: 0.04312917962670326\n",
      "train_loss: 0.0461866669356823\n",
      "train_loss: 0.04317896068096161\n",
      "train_loss: 0.048931628465652466\n",
      "train_loss: 0.04600024223327637\n",
      "train_loss: 0.046083927154541016\n",
      "train_loss: 0.04518286511301994\n",
      "train_loss: 0.038452256470918655\n",
      "train_loss: 0.03842882066965103\n",
      "train_loss: 0.040357720106840134\n",
      "train_loss: 0.045990753918886185\n",
      "train_loss: 0.041622091084718704\n",
      "train_loss: 0.04684341698884964\n",
      "train_loss: 0.040625348687171936\n",
      "train_loss: 0.044223852455616\n",
      "train_loss: 0.043525662273168564\n",
      "train_loss: 0.04652608186006546\n",
      "train_loss: 0.04401678964495659\n",
      "train_loss: 0.03941383585333824\n",
      "train_loss: 0.04142782464623451\n",
      "train_loss: 0.04247237741947174\n",
      "train_loss: 0.047642696648836136\n",
      "train_loss: 0.04562775045633316\n",
      "train_loss: 0.04568948969244957\n",
      "train_loss: 0.0433509536087513\n",
      "train_loss: 0.04311725124716759\n",
      "train_loss: 0.04595159366726875\n",
      "train_loss: 0.04087718576192856\n",
      "train_loss: 0.04515192285180092\n",
      "train_loss: 0.04718940332531929\n",
      "train_loss: 0.03804302215576172\n",
      "train_loss: 0.04299389570951462\n",
      "train_loss: 0.04431614652276039\n",
      "train_loss: 0.044353388249874115\n",
      "train_loss: 0.04725157469511032\n",
      "train_loss: 0.040622904896736145\n",
      "train_loss: 0.04008708521723747\n",
      "train_loss: 0.04198029637336731\n",
      "train_loss: 0.04613835737109184\n",
      "train_loss: 0.0453430712223053\n",
      "train_loss: 0.045701008290052414\n",
      "train_loss: 0.047280203551054\n",
      "train_loss: 0.04540514200925827\n",
      "train_loss: 0.045049719512462616\n",
      "train_loss: 0.046955496072769165\n",
      "train_loss: 0.0450064092874527\n",
      "train_loss: 0.0517730787396431\n",
      "train_loss: 0.04204683005809784\n",
      "train_loss: 0.04725966602563858\n",
      "train_loss: 0.04282262176275253\n",
      "train_loss: 0.046473581343889236\n",
      "train_loss: 0.045557957142591476\n",
      "train_loss: 0.03804617002606392\n",
      "train_loss: 0.04924541339278221\n",
      "train_loss: 0.045754026621580124\n",
      "train_loss: 0.04267220199108124\n",
      "train_loss: 0.04615164175629616\n",
      "train_loss: 0.046555809676647186\n",
      "train_loss: 0.04554919898509979\n",
      "train_loss: 0.04314770922064781\n",
      "train_loss: 0.04247622191905975\n",
      "train_loss: 0.045404791831970215\n",
      "train_loss: 0.046744100749492645\n",
      "train_loss: 0.04152650013566017\n",
      "train_loss: 0.047019630670547485\n",
      "train_loss: 0.052780792117118835\n",
      "train_loss: 0.046924564987421036\n",
      "train_loss: 0.0380767397582531\n",
      "train_loss: 0.04430186003446579\n",
      "train_loss: 0.04165757820010185\n",
      "train_loss: 0.04460812360048294\n",
      "train_loss: 0.04440436139702797\n",
      "train_loss: 0.04035782814025879\n",
      "train_loss: 0.047230564057826996\n",
      "train_loss: 0.0454389713704586\n",
      "train_loss: 0.04170546308159828\n",
      "train_loss: 0.04020041227340698\n",
      "train_loss: 0.04487920179963112\n",
      "train_loss: 0.0406925268471241\n",
      "train_loss: 0.04163622111082077\n",
      "train_loss: 0.04303150251507759\n",
      "train_loss: 0.03845053166151047\n",
      "train_loss: 0.04265187680721283\n",
      "train_loss: 0.03912453353404999\n",
      "train_loss: 0.04915925860404968\n",
      "train_loss: 0.043792080134153366\n",
      "train_loss: 0.040770672261714935\n",
      "train_loss: 0.04700522497296333\n",
      "train_loss: 0.04444417729973793\n",
      "train_loss: 0.04189196228981018\n",
      "train_loss: 0.04485917463898659\n",
      "train_loss: 0.043538033962249756\n",
      "train_loss: 0.044938649982213974\n",
      "train_loss: 0.04046321660280228\n",
      "train_loss: 0.042010609060525894\n",
      "train_loss: 0.04542503505945206\n",
      "train_loss: 0.044213876128196716\n",
      "train_loss: 0.03748127445578575\n",
      "train_loss: 0.04273197427392006\n",
      "train_loss: 0.04531920701265335\n",
      "train_loss: 0.04177882522344589\n",
      "train_loss: 0.04500070959329605\n",
      "train_loss: 0.044152501970529556\n",
      "train_loss: 0.04545208811759949\n",
      "train_loss: 0.05398602411150932\n",
      "train_loss: 0.0477224662899971\n",
      "train_loss: 0.04596038535237312\n",
      "train_loss: 0.04022156819701195\n",
      "train_loss: 0.04555537551641464\n",
      "train_loss: 0.04995909333229065\n",
      "train_loss: 0.0404592826962471\n",
      "train_loss: 0.044382113963365555\n",
      "train_loss: 0.04099941626191139\n",
      "train_loss: 0.04028743878006935\n",
      "train_loss: 0.04279400408267975\n",
      "train_loss: 0.041630543768405914\n",
      "train_loss: 0.04727966710925102\n",
      "train_loss: 0.04351944848895073\n",
      "train_loss: 0.04657428339123726\n",
      "train_loss: 0.04705675318837166\n",
      "train_loss: 0.046500157564878464\n",
      "train_loss: 0.05074390396475792\n",
      "train_loss: 0.04103891924023628\n",
      "train_loss: 0.04236849769949913\n",
      "train_loss: 0.03853602707386017\n",
      "train_loss: 0.03857399895787239\n",
      "train_loss: 0.044452451169490814\n",
      "train_loss: 0.03911176323890686\n",
      "train_loss: 0.04428881034255028\n",
      "train_loss: 0.048447735607624054\n",
      "train_loss: 0.04650405794382095\n",
      "train_loss: 0.041716624051332474\n",
      "train_loss: 0.04083838313817978\n",
      "train_loss: 0.04071756824851036\n",
      "train_loss: 0.044828470796346664\n",
      "train_loss: 0.04491685330867767\n",
      "train_loss: 0.050179895013570786\n",
      "train_loss: 0.04495106264948845\n",
      "train_loss: 0.04488197714090347\n",
      "train_loss: 0.038557883352041245\n",
      "train_loss: 0.04689035564661026\n",
      "train_loss: 0.040020592510700226\n",
      "train_loss: 0.047139160335063934\n",
      "train_loss: 0.04575180262327194\n",
      "train_loss: 0.04514414817094803\n",
      "train_loss: 0.04593053087592125\n",
      "train_loss: 0.040312137454748154\n",
      "train_loss: 0.04877172037959099\n",
      "train_loss: 0.038389015942811966\n",
      "train_loss: 0.04299401119351387\n",
      "train_loss: 0.04351806640625\n",
      "train_loss: 0.042187370359897614\n",
      "train_loss: 0.04412228614091873\n",
      "train_loss: 0.042684268206357956\n",
      "train_loss: 0.04777945205569267\n",
      "train_loss: 0.04200517013669014\n",
      "train_loss: 0.04670437052845955\n",
      "train_loss: 0.03853786736726761\n",
      "train_loss: 0.04117996618151665\n",
      "train_loss: 0.04741191864013672\n",
      "train_loss: 0.049765750765800476\n",
      "train_loss: 0.04635600000619888\n",
      "train_loss: 0.0435476116836071\n",
      "train_loss: 0.043788593262434006\n",
      "train_loss: 0.041401900351047516\n",
      "train_loss: 0.04208926111459732\n",
      "train_loss: 0.04379066079854965\n",
      "train_loss: 0.0448603630065918\n",
      "train_loss: 0.041614238172769547\n",
      "train_loss: 0.04164524003863335\n",
      "train_loss: 0.04364854469895363\n",
      "train_loss: 0.04219023138284683\n",
      "train_loss: 0.053870413452386856\n",
      "train_loss: 0.04694972559809685\n",
      "train_loss: 0.043749138712882996\n",
      "train_loss: 0.0444289930164814\n",
      "train_loss: 0.03966924920678139\n",
      "train_loss: 0.04486624896526337\n",
      "train_loss: 0.04348926246166229\n",
      "train_loss: 0.049361277371644974\n",
      "train_loss: 0.0454757995903492\n",
      "train_loss: 0.04062055051326752\n",
      "train_loss: 0.048046451061964035\n",
      "train_loss: 0.04637061804533005\n",
      "train_loss: 0.044503677636384964\n",
      "train_loss: 0.04432027414441109\n",
      "train_loss: 0.047741081565618515\n",
      "train_loss: 0.04447229579091072\n",
      "train_loss: 0.04394909739494324\n",
      "train_loss: 0.04445153847336769\n",
      "train_loss: 0.04103764519095421\n",
      "train_loss: 0.03868618234992027\n",
      "train_loss: 0.04288236424326897\n",
      "train_loss: 0.04524124786257744\n",
      "train_loss: 0.04915102198719978\n",
      "train_loss: 0.048191387206315994\n",
      "train_loss: 0.03960835933685303\n",
      "train_loss: 0.04359298199415207\n",
      "train_loss: 0.0399293377995491\n",
      "train_loss: 0.04690727964043617\n",
      "train_loss: 0.05181598663330078\n",
      "train_loss: 0.042360369116067886\n",
      "train_loss: 0.04667641222476959\n",
      "train_loss: 0.04058314114809036\n",
      "train_loss: 0.04292571544647217\n",
      "train_loss: 0.04588104784488678\n",
      "train_loss: 0.048190198838710785\n",
      "train_loss: 0.04263255000114441\n",
      "train_loss: 0.04721738398075104\n",
      "train_loss: 0.04461737349629402\n",
      "train_loss: 0.042835138738155365\n",
      "train_loss: 0.045131634920835495\n",
      "train_loss: 0.04653683304786682\n",
      "train_loss: 0.03814106807112694\n",
      "train_loss: 0.04277913272380829\n",
      "train_loss: 0.03637341782450676\n",
      "train_loss: 0.04199641942977905\n",
      "train_loss: 0.0442831814289093\n",
      "train_loss: 0.045227836817502975\n",
      "train_loss: 0.04552234709262848\n",
      "train_loss: 0.040624264627695084\n",
      "train_loss: 0.049069758504629135\n",
      "train_loss: 0.04056662693619728\n",
      "train_loss: 0.04574163630604744\n",
      "train_loss: 0.04274175688624382\n",
      "train_loss: 0.04070190712809563\n",
      "train_loss: 0.042745258659124374\n",
      "train_loss: 0.04203267768025398\n",
      "train_loss: 0.04473878815770149\n",
      "train_loss: 0.0441364161670208\n",
      "train_loss: 0.044667474925518036\n",
      "train_loss: 0.048608433455228806\n",
      "train_loss: 0.042137276381254196\n",
      "train_loss: 0.03529590368270874\n",
      "train_loss: 0.04277540743350983\n",
      "train_loss: 0.03826745226979256\n",
      "train_loss: 0.04115143418312073\n",
      "train_loss: 0.045667558908462524\n",
      "train_loss: 0.04146995395421982\n",
      "train_loss: 0.04431420937180519\n",
      "train_loss: 0.045159146189689636\n",
      "train_loss: 0.04450683295726776\n",
      "train_loss: 0.04307273030281067\n",
      "train_loss: 0.054476842284202576\n",
      "train_loss: 0.04496123641729355\n",
      "train_loss: 0.041878603398799896\n",
      "train_loss: 0.04435064271092415\n",
      "train_loss: 0.04045628011226654\n",
      "train_loss: 0.044602636247873306\n",
      "train_loss: 0.04785693809390068\n",
      "train_loss: 0.039536990225315094\n",
      "train_loss: 0.046287164092063904\n",
      "train_loss: 0.03880178555846214\n",
      "train_loss: 0.04955562204122543\n",
      "train_loss: 0.036640651524066925\n",
      "train_loss: 0.0435277596116066\n",
      "train_loss: 0.046115197241306305\n",
      "train_loss: 0.04701792448759079\n",
      "train_loss: 0.03831863775849342\n",
      "train_loss: 0.04643227532505989\n",
      "train_loss: 0.045039962977170944\n",
      "train_loss: 0.046588536351919174\n",
      "train_loss: 0.04355161264538765\n",
      "train_loss: 0.04562537372112274\n",
      "train_loss: 0.04358673840761185\n",
      "train_loss: 0.044822968542575836\n",
      "train_loss: 0.04679398983716965\n",
      "train_loss: 0.038817692548036575\n",
      "train_loss: 0.04703790321946144\n",
      "train_loss: 0.035811979323625565\n",
      "train_loss: 0.041999030858278275\n",
      "train_loss: 0.047732044011354446\n",
      "train_loss: 0.04560559615492821\n",
      "train_loss: 0.04927357658743858\n",
      "train_loss: 0.04130721092224121\n",
      "train_loss: 0.042178429663181305\n",
      "train_loss: 0.040706440806388855\n",
      "train_loss: 0.04302792623639107\n",
      "train_loss: 0.04122283309698105\n",
      "train_loss: 0.039253417402505875\n",
      "train_loss: 0.04562850296497345\n",
      "train_loss: 0.040383435785770416\n",
      "train_loss: 0.03992997109889984\n",
      "train_loss: 0.0452624075114727\n",
      "train_loss: 0.04237334802746773\n",
      "train_loss: 0.04990784451365471\n",
      "train_loss: 0.04611102491617203\n",
      "train_loss: 0.045283976942300797\n",
      "train_loss: 0.043541815131902695\n",
      "train_loss: 0.047970421612262726\n",
      "train_loss: 0.040878500789403915\n",
      "train_loss: 0.040172744542360306\n",
      "train_loss: 0.045948971062898636\n",
      "train_loss: 0.05308118462562561\n",
      "train_loss: 0.04738651216030121\n",
      "train_loss: 0.03805750980973244\n",
      "train_loss: 0.042387936264276505\n",
      "train_loss: 0.044335443526506424\n",
      "train_loss: 0.044800519943237305\n",
      "train_loss: 0.048833057284355164\n",
      "train_loss: 0.0433129146695137\n",
      "train_loss: 0.042141884565353394\n",
      "train_loss: 0.04167934134602547\n",
      "train_loss: 0.043359726667404175\n",
      "train_loss: 0.04606407508254051\n",
      "train_loss: 0.04618443548679352\n",
      "train_loss: 0.04625241085886955\n",
      "train_loss: 0.046307213604450226\n",
      "train_loss: 0.0429966002702713\n",
      "train_loss: 0.04938022419810295\n",
      "train_loss: 0.043624281883239746\n",
      "train_loss: 0.04239004850387573\n",
      "train_loss: 0.052310775965452194\n",
      "train_loss: 0.047722503542900085\n",
      "train_loss: 0.047394879162311554\n",
      "train_loss: 0.04426202550530434\n",
      "train_loss: 0.036333393305540085\n",
      "train_loss: 0.04112439975142479\n",
      "train_loss: 0.040821872651576996\n",
      "train_loss: 0.04646625742316246\n",
      "train_loss: 0.041055433452129364\n",
      "train_loss: 0.044108662754297256\n",
      "train_loss: 0.04046081751585007\n",
      "train_loss: 0.0443846769630909\n",
      "train_loss: 0.04308507218956947\n",
      "train_loss: 0.04148944467306137\n",
      "train_loss: 0.04150273650884628\n",
      "train_loss: 0.038624078035354614\n",
      "train_loss: 0.04344014823436737\n",
      "train_loss: 0.04208625108003616\n",
      "train_loss: 0.044553209096193314\n",
      "train_loss: 0.04259537532925606\n",
      "train_loss: 0.042688626796007156\n",
      "train_loss: 0.04147488623857498\n",
      "train_loss: 0.04213079437613487\n",
      "train_loss: 0.04517741501331329\n",
      "train_loss: 0.0415562279522419\n",
      "train_loss: 0.03968370705842972\n",
      "train_loss: 0.0416090227663517\n",
      "train_loss: 0.04695526510477066\n",
      "train_loss: 0.04617402330040932\n",
      "train_loss: 0.04054832458496094\n",
      "train_loss: 0.04302002489566803\n",
      "train_loss: 0.04315716400742531\n",
      "train_loss: 0.041035160422325134\n",
      "train_loss: 0.04148861765861511\n",
      "train_loss: 0.04175596684217453\n",
      "train_loss: 0.04841724783182144\n",
      "train_loss: 0.050111331045627594\n",
      "train_loss: 0.04259755089879036\n",
      "train_loss: 0.0466889925301075\n",
      "train_loss: 0.0456293448805809\n",
      "train_loss: 0.04252081736922264\n",
      "train_loss: 0.04255970939993858\n",
      "train_loss: 0.0472356341779232\n",
      "train_loss: 0.03743348643183708\n",
      "train_loss: 0.04172706604003906\n",
      "train_loss: 0.04511088505387306\n",
      "train_loss: 0.04024973511695862\n",
      "train_loss: 0.03953835368156433\n",
      "train_loss: 0.04689806327223778\n",
      "train_loss: 0.04184460639953613\n",
      "train_loss: 0.04406881704926491\n",
      "train_loss: 0.04162076115608215\n",
      "train_loss: 0.048278387635946274\n",
      "train_loss: 0.03957824409008026\n",
      "train_loss: 0.03981008753180504\n",
      "train_loss: 0.0466303825378418\n",
      "train_loss: 0.04562574252486229\n",
      "train_loss: 0.041238006204366684\n",
      "train_loss: 0.043140459805727005\n",
      "train_loss: 0.04391614720225334\n",
      "train_loss: 0.04578778147697449\n",
      "train_loss: 0.041967738419771194\n",
      "train_loss: 0.04203547537326813\n",
      "train_loss: 0.04334003105759621\n",
      "train_loss: 0.0405668243765831\n",
      "train_loss: 0.043786756694316864\n",
      "train_loss: 0.043007999658584595\n",
      "train_loss: 0.043000075966119766\n",
      "train_loss: 0.043819162994623184\n",
      "train_loss: 0.045506786555051804\n",
      "train_loss: 0.04411130025982857\n",
      "train_loss: 0.040410201996564865\n",
      "train_loss: 0.04675505682826042\n",
      "train_loss: 0.041984643787145615\n",
      "train_loss: 0.04266802966594696\n",
      "train_loss: 0.04150240495800972\n",
      "train_loss: 0.050473786890506744\n",
      "train_loss: 0.03810613974928856\n",
      "train_loss: 0.04887942597270012\n",
      "train_loss: 0.04100008308887482\n",
      "train_loss: 0.044151339679956436\n",
      "train_loss: 0.04251156002283096\n",
      "train_loss: 0.04458276927471161\n",
      "train_loss: 0.04069142043590546\n",
      "train_loss: 0.04156427085399628\n",
      "train_loss: 0.04222638159990311\n",
      "train_loss: 0.041542183607816696\n",
      "train_loss: 0.04639407619833946\n",
      "train_loss: 0.04529546946287155\n",
      "train_loss: 0.03786729276180267\n",
      "train_loss: 0.043557196855545044\n",
      "train_loss: 0.03902279585599899\n",
      "train_loss: 0.04482525214552879\n",
      "train_loss: 0.04625513404607773\n",
      "train_loss: 0.037642478942871094\n",
      "train_loss: 0.04583880305290222\n",
      "train_loss: 0.044259022921323776\n",
      "train_loss: 0.0396050363779068\n",
      "train_loss: 0.043555084615945816\n",
      "train_loss: 0.04250991344451904\n",
      "train_loss: 0.04304109513759613\n",
      "train_loss: 0.04467756301164627\n",
      "train_loss: 0.04482187330722809\n",
      "train_loss: 0.0404660664498806\n",
      "train_loss: 0.04434749856591225\n",
      "train_loss: 0.045404061675071716\n",
      "train_loss: 0.049393799155950546\n",
      "train_loss: 0.04676051810383797\n",
      "train_loss: 0.04785972461104393\n",
      "train_loss: 0.045665349811315536\n",
      "train_loss: 0.04232252761721611\n",
      "train_loss: 0.051985446363687515\n",
      "train_loss: 0.0491468608379364\n",
      "train_loss: 0.04601297155022621\n",
      "train_loss: 0.04170576483011246\n",
      "train_loss: 0.043831244111061096\n",
      "train_loss: 0.04391501471400261\n",
      "train_loss: 0.03829603269696236\n",
      "train_loss: 0.04422192648053169\n",
      "train_loss: 0.04486926272511482\n",
      "train_loss: 0.042374689131975174\n",
      "train_loss: 0.04197216406464577\n",
      "train_loss: 0.0438658744096756\n",
      "train_loss: 0.04199959710240364\n",
      "train_loss: 0.047937698662281036\n",
      "train_loss: 0.039905522018671036\n",
      "train_loss: 0.042267147451639175\n",
      "train_loss: 0.04206320270895958\n",
      "train_loss: 0.04556833952665329\n",
      "train_loss: 0.041119836270809174\n",
      "train_loss: 0.04119278863072395\n",
      "train_loss: 0.039012011140584946\n",
      "train_loss: 0.038004111498594284\n",
      "train_loss: 0.04700634256005287\n",
      "train_loss: 0.044801391661167145\n",
      "train_loss: 0.04178611934185028\n",
      "train_loss: 0.04221291467547417\n",
      "train_loss: 0.04460395127534866\n",
      "train_loss: 0.04606221616268158\n",
      "train_loss: 0.0416824035346508\n",
      "train_loss: 0.04116813465952873\n",
      "train_loss: 0.04443544149398804\n",
      "train_loss: 0.03755521774291992\n",
      "train_loss: 0.04718328267335892\n",
      "train_loss: 0.04273315146565437\n",
      "train_loss: 0.04674568027257919\n",
      "train_loss: 0.048106636852025986\n",
      "train_loss: 0.04595116525888443\n",
      "train_loss: 0.044374868273735046\n",
      "train_loss: 0.04236575961112976\n",
      "train_loss: 0.04013996943831444\n",
      "train_loss: 0.04492897167801857\n",
      "train_loss: 0.048691779375076294\n",
      "train_loss: 0.046913910657167435\n",
      "train_loss: 0.04052275791764259\n",
      "train_loss: 0.044094983488321304\n",
      "train_loss: 0.0447232648730278\n",
      "train_loss: 0.044807709753513336\n",
      "train_loss: 0.04734877124428749\n",
      "train_loss: 0.041734252125024796\n",
      "train_loss: 0.045069821178913116\n",
      "train_loss: 0.045286186039447784\n",
      "train_loss: 0.037683192640542984\n",
      "train_loss: 0.05027136579155922\n",
      "train_loss: 0.0392119474709034\n",
      "train_loss: 0.037349503487348557\n",
      "train_loss: 0.040449608117341995\n",
      "train_loss: 0.04155629500746727\n",
      "train_loss: 0.0453171543776989\n",
      "train_loss: 0.037432651966810226\n",
      "train_loss: 0.04030531272292137\n",
      "train_loss: 0.03749631345272064\n",
      "train_loss: 0.04109174385666847\n",
      "train_loss: 0.042192935943603516\n",
      "train_loss: 0.041559528559446335\n",
      "train_loss: 0.0374753400683403\n",
      "train_loss: 0.03939741477370262\n",
      "train_loss: 0.043862245976924896\n",
      "train_loss: 0.04121316969394684\n",
      "train_loss: 0.0460127592086792\n",
      "train_loss: 0.04292380064725876\n",
      "train_loss: 0.046100713312625885\n",
      "train_loss: 0.04681942239403725\n",
      "train_loss: 0.048268310725688934\n",
      "train_loss: 0.040201712399721146\n",
      "train_loss: 0.042794980108737946\n",
      "train_loss: 0.04495340213179588\n",
      "train_loss: 0.0446486659348011\n",
      "train_loss: 0.04274934530258179\n",
      "train_loss: 0.04290026053786278\n",
      "train_loss: 0.04250728338956833\n",
      "train_loss: 0.04300211742520332\n",
      "train_loss: 0.039046384394168854\n",
      "train_loss: 0.041976407170295715\n",
      "train_loss: 0.04571104049682617\n",
      "train_loss: 0.04169534519314766\n",
      "train_loss: 0.037634603679180145\n",
      "train_loss: 0.0449710339307785\n",
      "train_loss: 0.04220830276608467\n",
      "train_loss: 0.04316312447190285\n",
      "train_loss: 0.043148186057806015\n",
      "train_loss: 0.045765358954668045\n",
      "train_loss: 0.03785308077931404\n",
      "train_loss: 0.04590016230940819\n",
      "train_loss: 0.0437445230782032\n",
      "train_loss: 0.0412198081612587\n",
      "train_loss: 0.04331846535205841\n",
      "train_loss: 0.04029944911599159\n",
      "train_loss: 0.03826039284467697\n",
      "train_loss: 0.043006252497434616\n",
      "train_loss: 0.03801315650343895\n",
      "train_loss: 0.04484952613711357\n",
      "train_loss: 0.041373927146196365\n",
      "train_loss: 0.04899271950125694\n",
      "train_loss: 0.036915797740221024\n",
      "train_loss: 0.042718540877103806\n",
      "train_loss: 0.04245787113904953\n",
      "train_loss: 0.0459572933614254\n",
      "train_loss: 0.03966432437300682\n",
      "train_loss: 0.04023540019989014\n",
      "train_loss: 0.04497436434030533\n",
      "train_loss: 0.04304911941289902\n",
      "train_loss: 0.0404248870909214\n",
      "train_loss: 0.04553572088479996\n",
      "train_loss: 0.04504159092903137\n",
      "train_loss: 0.03886917978525162\n",
      "train_loss: 0.044669732451438904\n",
      "train_loss: 0.0426509715616703\n",
      "train_loss: 0.04358799383044243\n",
      "train_loss: 0.04884390905499458\n",
      "train_loss: 0.0427665114402771\n",
      "train_loss: 0.04198950156569481\n",
      "train_loss: 0.04723334684967995\n",
      "train_loss: 0.045645877718925476\n",
      "train_loss: 0.045499999076128006\n",
      "train_loss: 0.041679497808218\n",
      "train_loss: 0.04655574634671211\n",
      "train_loss: 0.04764045029878616\n",
      "train_loss: 0.044228795915842056\n",
      "train_loss: 0.04097389429807663\n",
      "train_loss: 0.04319341108202934\n",
      "train_loss: 0.04582202062010765\n",
      "train_loss: 0.04255582392215729\n",
      "train_loss: 0.04492843151092529\n",
      "train_loss: 0.04342181235551834\n",
      "train_loss: 0.040454037487506866\n",
      "train_loss: 0.03824201971292496\n",
      "train_loss: 0.039715059101581573\n",
      "train_loss: 0.046115562319755554\n",
      "train_loss: 0.05112606659531593\n",
      "train_loss: 0.043751414865255356\n",
      "train_loss: 0.04055609926581383\n",
      "train_loss: 0.03331610560417175\n",
      "train_loss: 0.044710271060466766\n",
      "train_loss: 0.04156331717967987\n",
      "train_loss: 0.04811236262321472\n",
      "train_loss: 0.036765359342098236\n",
      "train_loss: 0.04493948444724083\n",
      "train_loss: 0.04093216359615326\n",
      "train_loss: 0.039790499955415726\n",
      "train_loss: 0.0343809574842453\n",
      "train_loss: 0.046400196850299835\n",
      "train_loss: 0.04196717590093613\n",
      "train_loss: 0.04144905135035515\n",
      "train_loss: 0.0451725572347641\n",
      "train_loss: 0.04549609124660492\n",
      "train_loss: 0.04552634805440903\n",
      "train_loss: 0.04589943587779999\n",
      "train_loss: 0.047852110117673874\n",
      "train_loss: 0.04354674741625786\n",
      "train_loss: 0.04001300036907196\n",
      "train_loss: 0.04845605418086052\n",
      "train_loss: 0.04773328825831413\n",
      "train_loss: 0.04302997514605522\n",
      "train_loss: 0.04223111271858215\n",
      "train_loss: 0.040181707590818405\n",
      "train_loss: 0.047219887375831604\n",
      "train_loss: 0.041250042617321014\n",
      "train_loss: 0.04449711740016937\n",
      "train_loss: 0.04685787484049797\n",
      "train_loss: 0.042081646621227264\n",
      "train_loss: 0.043311625719070435\n",
      "train_loss: 0.04058916121721268\n",
      "train_loss: 0.03974131494760513\n",
      "train_loss: 0.046355392783880234\n",
      "train_loss: 0.04172367975115776\n",
      "train_loss: 0.03919856622815132\n",
      "train_loss: 0.041354041546583176\n",
      "train_loss: 0.03793831169605255\n",
      "train_loss: 0.047663141041994095\n",
      "train_loss: 0.041275378316640854\n",
      "train_loss: 0.048656608909368515\n",
      "train_loss: 0.041807856410741806\n",
      "train_loss: 0.04872317239642143\n",
      "train_loss: 0.040976572781801224\n",
      "train_loss: 0.04387044906616211\n",
      "train_loss: 0.041150737553834915\n",
      "train_loss: 0.040310874581336975\n",
      "train_loss: 0.0434643030166626\n",
      "train_loss: 0.047506242990493774\n",
      "train_loss: 0.038464680314064026\n",
      "train_loss: 0.041366640478372574\n",
      "train_loss: 0.042878683656454086\n",
      "train_loss: 0.04128850996494293\n",
      "train_loss: 0.03974009305238724\n",
      "train_loss: 0.03992044925689697\n",
      "train_loss: 0.044728633016347885\n",
      "train_loss: 0.04491717740893364\n",
      "train_loss: 0.04643898457288742\n",
      "train_loss: 0.041548434644937515\n",
      "train_loss: 0.04211423918604851\n",
      "train_loss: 0.04249121621251106\n",
      "train_loss: 0.04347636550664902\n",
      "train_loss: 0.04273402318358421\n",
      "train_loss: 0.04358183592557907\n",
      "train_loss: 0.03655318170785904\n",
      "train_loss: 0.03847586363554001\n",
      "train_loss: 0.03852875530719757\n",
      "train_loss: 0.050321005284786224\n",
      "train_loss: 0.0431012399494648\n",
      "train_loss: 0.04118134081363678\n",
      "train_loss: 0.04211786761879921\n",
      "train_loss: 0.04940585419535637\n",
      "train_loss: 0.04444871470332146\n",
      "train_loss: 0.0496877059340477\n",
      "train_loss: 0.04067094251513481\n",
      "train_loss: 0.04528115317225456\n",
      "train_loss: 0.04463138431310654\n",
      "train_loss: 0.04027514159679413\n",
      "train_loss: 0.04424551501870155\n",
      "train_loss: 0.045526862144470215\n",
      "train_loss: 0.04582514986395836\n",
      "train_loss: 0.04371177405118942\n",
      "train_loss: 0.0457119345664978\n",
      "train_loss: 0.04932165890932083\n",
      "train_loss: 0.03877755254507065\n",
      "train_loss: 0.046452540904283524\n",
      "train_loss: 0.038546089082956314\n",
      "train_loss: 0.04439233988523483\n",
      "train_loss: 0.04275277256965637\n",
      "train_loss: 0.04763442650437355\n",
      "train_loss: 0.04288356378674507\n",
      "train_loss: 0.037384577095508575\n",
      "train_loss: 0.0367630198597908\n",
      "train_loss: 0.042053379118442535\n",
      "train_loss: 0.04374827444553375\n",
      "train_loss: 0.038151077926158905\n",
      "train_loss: 0.03947968780994415\n",
      "train_loss: 0.04824330657720566\n",
      "train_loss: 0.04403379559516907\n",
      "train_loss: 0.042084112763404846\n",
      "train_loss: 0.03661813586950302\n",
      "train_loss: 0.041141021996736526\n",
      "train_loss: 0.037854231894016266\n",
      "train_loss: 0.04130316525697708\n",
      "train_loss: 0.036063630133867264\n",
      "train_loss: 0.04176662489771843\n",
      "train_loss: 0.04474494233727455\n",
      "train_loss: 0.046744633466005325\n",
      "train_loss: 0.0410575307905674\n",
      "train_loss: 0.04457790032029152\n",
      "train_loss: 0.038166724145412445\n",
      "train_loss: 0.040202219039201736\n",
      "train_loss: 0.047006674110889435\n",
      "train_loss: 0.04318942129611969\n",
      "train_loss: 0.03754664957523346\n",
      "train_loss: 0.04105756804347038\n",
      "train_loss: 0.04374898225069046\n",
      "train_loss: 0.04282582551240921\n",
      "train_loss: 0.04674486443400383\n",
      "train_loss: 0.043193671852350235\n",
      "train_loss: 0.040625978261232376\n",
      "train_loss: 0.04000581055879593\n",
      "train_loss: 0.038686688989400864\n",
      "train_loss: 0.04259954020380974\n",
      "train_loss: 0.04252626374363899\n",
      "train_loss: 0.04555954039096832\n",
      "train_loss: 0.03769500181078911\n",
      "train_loss: 0.041933439671993256\n",
      "train_loss: 0.04136160761117935\n",
      "train_loss: 0.04520866274833679\n",
      "train_loss: 0.037976592779159546\n",
      "train_loss: 0.047835417091846466\n",
      "train_loss: 0.04516162723302841\n",
      "train_loss: 0.04289944842457771\n",
      "train_loss: 0.04335454851388931\n",
      "train_loss: 0.03978617861866951\n",
      "train_loss: 0.036904819309711456\n",
      "train_loss: 0.04607002064585686\n",
      "train_loss: 0.03763000667095184\n",
      "train_loss: 0.040831059217453\n",
      "train_loss: 0.04717326536774635\n",
      "train_loss: 0.04801559820771217\n",
      "train_loss: 0.044103652238845825\n",
      "train_loss: 0.04189113527536392\n",
      "train_loss: 0.04043303802609444\n",
      "train_loss: 0.041060276329517365\n",
      "train_loss: 0.042761120945215225\n",
      "train_loss: 0.04073232039809227\n",
      "train_loss: 0.04638322442770004\n",
      "train_loss: 0.04158073291182518\n",
      "train_loss: 0.04525696858763695\n",
      "train_loss: 0.04458148032426834\n",
      "train_loss: 0.04218380153179169\n",
      "train_loss: 0.04285745695233345\n",
      "train_loss: 0.04082471504807472\n",
      "train_loss: 0.04313087463378906\n",
      "train_loss: 0.04117335006594658\n",
      "train_loss: 0.04494320601224899\n",
      "train_loss: 0.04141301289200783\n",
      "train_loss: 0.04349420592188835\n",
      "train_loss: 0.04044557362794876\n",
      "train_loss: 0.04320250451564789\n",
      "train_loss: 0.04239868372678757\n",
      "train_loss: 0.04213859513401985\n",
      "train_loss: 0.047899030148983\n",
      "train_loss: 0.04177691787481308\n",
      "train_loss: 0.041216883808374405\n",
      "train_loss: 0.04105231538414955\n",
      "train_loss: 0.03757404908537865\n",
      "train_loss: 0.04665151983499527\n",
      "train_loss: 0.0411502867937088\n",
      "train_loss: 0.03715885803103447\n",
      "train_loss: 0.04223503917455673\n",
      "train_loss: 0.04294221103191376\n",
      "train_loss: 0.04442184045910835\n",
      "train_loss: 0.03894286975264549\n",
      "train_loss: 0.04173741117119789\n",
      "train_loss: 0.04252428933978081\n",
      "train_loss: 0.04183952137827873\n",
      "train_loss: 0.04349089041352272\n",
      "train_loss: 0.04175884649157524\n",
      "train_loss: 0.03909076750278473\n",
      "train_loss: 0.03865140676498413\n",
      "train_loss: 0.045819710940122604\n",
      "train_loss: 0.042930491268634796\n",
      "train_loss: 0.04857100173830986\n",
      "train_loss: 0.04182817041873932\n",
      "train_loss: 0.04571404680609703\n",
      "train_loss: 0.04567903280258179\n",
      "train_loss: 0.042834192514419556\n",
      "train_loss: 0.04448183253407478\n",
      "train_loss: 0.041310522705316544\n",
      "train_loss: 0.041974276304244995\n",
      "train_loss: 0.044807665050029755\n",
      "train_loss: 0.03808216005563736\n",
      "train_loss: 0.043080948293209076\n",
      "train_loss: 0.0446898452937603\n",
      "train_loss: 0.0422416590154171\n",
      "train_loss: 0.03842930495738983\n",
      "train_loss: 0.038494836539030075\n",
      "train_loss: 0.0421895831823349\n",
      "train_loss: 0.04122010990977287\n",
      "train_loss: 0.04600938409566879\n",
      "train_loss: 0.04197978973388672\n",
      "train_loss: 0.041561949998140335\n",
      "train_loss: 0.04443681240081787\n",
      "train_loss: 0.046137113124132156\n",
      "train_loss: 0.0455121286213398\n",
      "train_loss: 0.04538952559232712\n",
      "train_loss: 0.04170144349336624\n",
      "train_loss: 0.041760511696338654\n",
      "train_loss: 0.036544084548950195\n",
      "train_loss: 0.04577256739139557\n",
      "train_loss: 0.04149187356233597\n",
      "train_loss: 0.037250835448503494\n",
      "train_loss: 0.044798314571380615\n",
      "train_loss: 0.04427150636911392\n",
      "train_loss: 0.03814592584967613\n",
      "train_loss: 0.043343931436538696\n",
      "train_loss: 0.04265200346708298\n",
      "train_loss: 0.04617012292146683\n",
      "train_loss: 0.0413232184946537\n",
      "train_loss: 0.040869176387786865\n",
      "train_loss: 0.044332027435302734\n",
      "train_loss: 0.04150460287928581\n",
      "train_loss: 0.04173893854022026\n",
      "train_loss: 0.04476810246706009\n",
      "train_loss: 0.04234971106052399\n",
      "train_loss: 0.04360225051641464\n",
      "train_loss: 0.04312531650066376\n",
      "train_loss: 0.042767517268657684\n",
      "train_loss: 0.03689274191856384\n",
      "train_loss: 0.047961700707674026\n",
      "train_loss: 0.04131985083222389\n",
      "train_loss: 0.039059292525053024\n",
      "train_loss: 0.04631565883755684\n",
      "train_loss: 0.0422501303255558\n",
      "train_loss: 0.04274551942944527\n",
      "train_loss: 0.04418405517935753\n",
      "train_loss: 0.04081471264362335\n",
      "train_loss: 0.036816440522670746\n",
      "train_loss: 0.04232505336403847\n",
      "train_loss: 0.04665708914399147\n",
      "train_loss: 0.043072573840618134\n",
      "train_loss: 0.04229346662759781\n",
      "train_loss: 0.04076826572418213\n",
      "train_loss: 0.03998854011297226\n",
      "train_loss: 0.043009813874959946\n",
      "train_loss: 0.04482397064566612\n",
      "train_loss: 0.04204379767179489\n",
      "train_loss: 0.043286390602588654\n",
      "train_loss: 0.044417936354875565\n",
      "train_loss: 0.04496016353368759\n",
      "train_loss: 0.042367175221443176\n",
      "train_loss: 0.047202061861753464\n",
      "train_loss: 0.043209027498960495\n",
      "train_loss: 0.044885944575071335\n",
      "train_loss: 0.03936472535133362\n",
      "train_loss: 0.04170442000031471\n",
      "train_loss: 0.03895653039216995\n",
      "train_loss: 0.046300649642944336\n",
      "train_loss: 0.04957226291298866\n",
      "train_loss: 0.03985590115189552\n",
      "train_loss: 0.04080294817686081\n",
      "train_loss: 0.03874726593494415\n",
      "train_loss: 0.03613670542836189\n",
      "train_loss: 0.041084375232458115\n",
      "train_loss: 0.0402359776198864\n",
      "train_loss: 0.05173572152853012\n",
      "train_loss: 0.04224293306469917\n",
      "train_loss: 0.04184975475072861\n",
      "train_loss: 0.04112304002046585\n",
      "train_loss: 0.04949435964226723\n",
      "train_loss: 0.04112909361720085\n",
      "train_loss: 0.03988896682858467\n",
      "train_loss: 0.04885624721646309\n",
      "train_loss: 0.04867429658770561\n",
      "train_loss: 0.03860602527856827\n",
      "train_loss: 0.04474860802292824\n",
      "train_loss: 0.0437980554997921\n",
      "train_loss: 0.03879966959357262\n",
      "train_loss: 0.04231403395533562\n",
      "train_loss: 0.04041937738656998\n",
      "train_loss: 0.04644572362303734\n",
      "train_loss: 0.04171245917677879\n",
      "train_loss: 0.04710368439555168\n",
      "train_loss: 0.0464547798037529\n",
      "train_loss: 0.04065697267651558\n",
      "train_loss: 0.03456108272075653\n",
      "train_loss: 0.041543882340192795\n",
      "train_loss: 0.04450766369700432\n",
      "train_loss: 0.04476113244891167\n",
      "train_loss: 0.04184190556406975\n",
      "train_loss: 0.04224660247564316\n",
      "train_loss: 0.04210390895605087\n",
      "train_loss: 0.04490938037633896\n",
      "train_loss: 0.037341486662626266\n",
      "train_loss: 0.044018346816301346\n",
      "train_loss: 0.0416983962059021\n",
      "train_loss: 0.04780192673206329\n",
      "train_loss: 0.048640649765729904\n",
      "train_loss: 0.03732029348611832\n",
      "train_loss: 0.04137934371829033\n",
      "train_loss: 0.04140622168779373\n",
      "train_loss: 0.0378304086625576\n",
      "train_loss: 0.042793065309524536\n",
      "train_loss: 0.044432152062654495\n",
      "train_loss: 0.042412251234054565\n",
      "train_loss: 0.042031269520521164\n",
      "train_loss: 0.04819031432271004\n",
      "train_loss: 0.04200274497270584\n",
      "train_loss: 0.0444779247045517\n",
      "train_loss: 0.03967317193746567\n",
      "train_loss: 0.043362393975257874\n",
      "train_loss: 0.04050720855593681\n",
      "train_loss: 0.0470549575984478\n",
      "train_loss: 0.03542185574769974\n",
      "train_loss: 0.035830531269311905\n",
      "train_loss: 0.039591606706380844\n",
      "train_loss: 0.049541208893060684\n",
      "train_loss: 0.044000059366226196\n",
      "train_loss: 0.0449734590947628\n",
      "train_loss: 0.04453596845269203\n",
      "train_loss: 0.041291333734989166\n",
      "train_loss: 0.045767322182655334\n",
      "train_loss: 0.04804106429219246\n",
      "train_loss: 0.03839816898107529\n",
      "train_loss: 0.03919610008597374\n",
      "train_loss: 0.043364349752664566\n",
      "train_loss: 0.04080907627940178\n",
      "train_loss: 0.044125672429800034\n",
      "train_loss: 0.04049716144800186\n",
      "train_loss: 0.04532812535762787\n",
      "train_loss: 0.03956464305520058\n",
      "train_loss: 0.04405586048960686\n",
      "train_loss: 0.04353034496307373\n",
      "train_loss: 0.04404497146606445\n",
      "train_loss: 0.04259727522730827\n",
      "train_loss: 0.04344434663653374\n",
      "train_loss: 0.04258899763226509\n",
      "train_loss: 0.047310128808021545\n",
      "train_loss: 0.04151870682835579\n",
      "train_loss: 0.04939356446266174\n",
      "train_loss: 0.04113146290183067\n",
      "train_loss: 0.041922248899936676\n",
      "train_loss: 0.04000896215438843\n",
      "train_loss: 0.04069794714450836\n",
      "train_loss: 0.042451340705156326\n",
      "train_loss: 0.039884455502033234\n",
      "train_loss: 0.03752754256129265\n",
      "train_loss: 0.04250727966427803\n",
      "train_loss: 0.04231494665145874\n",
      "train_loss: 0.04424246773123741\n",
      "train_loss: 0.04315389692783356\n",
      "train_loss: 0.04140472784638405\n",
      "train_loss: 0.04261438921093941\n",
      "train_loss: 0.04250441864132881\n",
      "train_loss: 0.04588433727622032\n",
      "train_loss: 0.04126594588160515\n",
      "train_loss: 0.04072294011712074\n",
      "train_loss: 0.038404084742069244\n",
      "train_loss: 0.04318506643176079\n",
      "train_loss: 0.04719804599881172\n",
      "train_loss: 0.04254617542028427\n",
      "train_loss: 0.042156416922807693\n",
      "train_loss: 0.037706851959228516\n",
      "train_loss: 0.04391736164689064\n",
      "train_loss: 0.042312368750572205\n",
      "train_loss: 0.04294733703136444\n",
      "train_loss: 0.04221368581056595\n",
      "train_loss: 0.04062780365347862\n",
      "train_loss: 0.04340384528040886\n",
      "train_loss: 0.045828498899936676\n",
      "train_loss: 0.04573146626353264\n",
      "train_loss: 0.043629273772239685\n",
      "train_loss: 0.04135603830218315\n",
      "train_loss: 0.04525650292634964\n",
      "train_loss: 0.036487869918346405\n",
      "train_loss: 0.043361078947782516\n",
      "train_loss: 0.041073232889175415\n",
      "train_loss: 0.043182000517845154\n",
      "train_loss: 0.042343538254499435\n",
      "train_loss: 0.044306375086307526\n",
      "train_loss: 0.04482131078839302\n",
      "train_loss: 0.04114606976509094\n",
      "train_loss: 0.04611745476722717\n",
      "train_loss: 0.038017384707927704\n",
      "train_loss: 0.041032202541828156\n",
      "train_loss: 0.04090595245361328\n",
      "train_loss: 0.03817875683307648\n",
      "train_loss: 0.04551095888018608\n",
      "train_loss: 0.038249481469392776\n",
      "train_loss: 0.03909781575202942\n",
      "train_loss: 0.04192831367254257\n",
      "train_loss: 0.04060322791337967\n",
      "train_loss: 0.04454278200864792\n",
      "train_loss: 0.04717869684100151\n",
      "train_loss: 0.04246845096349716\n",
      "train_loss: 0.04477382078766823\n",
      "train_loss: 0.042491115629673004\n",
      "train_loss: 0.04200190305709839\n",
      "train_loss: 0.0414041206240654\n",
      "train_loss: 0.04591091349720955\n",
      "train_loss: 0.041737109422683716\n",
      "train_loss: 0.04756893217563629\n",
      "train_loss: 0.042416784912347794\n",
      "train_loss: 0.0411587618291378\n",
      "train_loss: 0.0406770184636116\n",
      "train_loss: 0.04618144407868385\n",
      "train_loss: 0.04141155630350113\n",
      "train_loss: 0.04628266021609306\n",
      "train_loss: 0.03979349881410599\n",
      "train_loss: 0.03916190192103386\n",
      "train_loss: 0.03893835470080376\n",
      "train_loss: 0.03863713517785072\n",
      "train_loss: 0.04095769673585892\n",
      "train_loss: 0.039718784391880035\n",
      "train_loss: 0.04090295359492302\n",
      "train_loss: 0.046017732471227646\n",
      "train_loss: 0.040260378271341324\n",
      "train_loss: 0.04155762866139412\n",
      "train_loss: 0.04876824840903282\n",
      "train_loss: 0.04193719103932381\n",
      "train_loss: 0.03564634174108505\n",
      "train_loss: 0.04169992357492447\n",
      "train_loss: 0.04296856373548508\n",
      "train_loss: 0.04036871716380119\n",
      "train_loss: 0.04409518837928772\n",
      "train_loss: 0.038284145295619965\n",
      "train_loss: 0.041071001440286636\n",
      "train_loss: 0.0420357882976532\n",
      "train_loss: 0.04404989629983902\n",
      "train_loss: 0.04109453409910202\n",
      "train_loss: 0.047546472400426865\n",
      "train_loss: 0.04128437489271164\n",
      "train_loss: 0.042468126863241196\n",
      "train_loss: 0.037415556609630585\n",
      "train_loss: 0.04107217490673065\n",
      "train_loss: 0.045099448412656784\n",
      "train_loss: 0.043469443917274475\n",
      "train_loss: 0.04306207597255707\n",
      "train_loss: 0.04888118430972099\n",
      "train_loss: 0.04717965051531792\n",
      "train_loss: 0.038209471851587296\n",
      "train_loss: 0.04197690263390541\n",
      "train_loss: 0.04008682817220688\n",
      "train_loss: 0.04279957711696625\n",
      "train_loss: 0.03941582515835762\n",
      "train_loss: 0.04436517506837845\n",
      "train_loss: 0.043516192585229874\n",
      "train_loss: 0.041882745921611786\n",
      "train_loss: 0.03851928934454918\n",
      "train_loss: 0.04806377366185188\n",
      "train_loss: 0.03915533050894737\n",
      "train_loss: 0.042327091097831726\n",
      "train_loss: 0.03855118900537491\n",
      "train_loss: 0.042619869112968445\n",
      "train_loss: 0.04168757051229477\n",
      "train_loss: 0.044972021132707596\n",
      "train_loss: 0.04512380063533783\n",
      "train_loss: 0.04211623594164848\n",
      "train_loss: 0.045594848692417145\n",
      "train_loss: 0.041003305464982986\n",
      "train_loss: 0.038597315549850464\n",
      "train_loss: 0.045486196875572205\n",
      "train_loss: 0.048272084444761276\n",
      "train_loss: 0.037492457777261734\n",
      "train_loss: 0.042570170015096664\n",
      "train_loss: 0.03876128047704697\n",
      "train_loss: 0.044688671827316284\n",
      "train_loss: 0.04395727068185806\n",
      "train_loss: 0.0406704880297184\n",
      "train_loss: 0.04400893673300743\n",
      "train_loss: 0.04520830884575844\n",
      "train_loss: 0.0410478338599205\n",
      "train_loss: 0.04143573343753815\n",
      "train_loss: 0.046649858355522156\n",
      "train_loss: 0.0427955687046051\n",
      "train_loss: 0.04110363498330116\n",
      "train_loss: 0.042812276631593704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.03918258100748062\n",
      "train_loss: 0.048604048788547516\n",
      "train_loss: 0.03833622485399246\n",
      "train_loss: 0.04008423537015915\n",
      "train_loss: 0.040796250104904175\n",
      "train_loss: 0.041862428188323975\n",
      "train_loss: 0.039605725556612015\n",
      "train_loss: 0.04285390302538872\n",
      "train_loss: 0.04430767893791199\n",
      "train_loss: 0.04532242566347122\n",
      "train_loss: 0.04274338111281395\n",
      "train_loss: 0.03967258334159851\n",
      "train_loss: 0.039830755442380905\n",
      "train_loss: 0.03838515281677246\n",
      "train_loss: 0.04989895597100258\n",
      "train_loss: 0.04129233583807945\n",
      "train_loss: 0.04614856839179993\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "dataset = MNIST(root='./data', download=True, transform=ToTensor())\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# trainer\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "trainer.fit(model=ae, train_dataloaders=train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
