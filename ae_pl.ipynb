{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An example of autoencoder (AE) with pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# library\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import Tensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model: 784 -> 64 -> 3 -> 64 -> 784\n",
    "encoder = nn.Sequential(nn.Linear(28 * 28, 64), \n",
    "                        nn.ReLU(), \n",
    "                        nn.Linear(64, 3))\n",
    "decoder = nn.Sequential(nn.Linear(3, 64), \n",
    "                        nn.ReLU(), \n",
    "                        nn.Linear(64, 28 * 28))\n",
    "\n",
    "class LitAutoEncoder(pl.LightningModule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        x = x.view(x.size(0), -1)\n",
    "        z = self.encoder(x)\n",
    "        x_hat = self.decoder(z)\n",
    "        loss = F.mse_loss(x_hat, x)\n",
    "        # Include extra logging here\n",
    "        self.log('train_loss', loss)\n",
    "        print(f'train_loss: {loss}')\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=0.001)\n",
    "        return optimizer\n",
    "\n",
    "ae = LitAutoEncoder(encoder, decoder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:14<00:00, 678687.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 117479.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:02<00:00, 668030.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 2315892.14it/s]\n",
      "Trainer will use only 1 of 2 GPUs because it is running inside an interactive / notebook environment. You may try to set `Trainer(devices=2)` but please note that multi-GPU inside interactive / notebook environments is considered experimental and unstable. Your mileage may vary.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "Missing logger folder: /mnt/nas/augix/sandbox/mnist_ae/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n",
      "\n",
      "  | Name    | Type       | Params\n",
      "---------------------------------------\n",
      "0 | encoder | Sequential | 50.4 K\n",
      "1 | decoder | Sequential | 51.2 K\n",
      "---------------------------------------\n",
      "101 K     Trainable params\n",
      "0         Non-trainable params\n",
      "101 K     Total params\n",
      "0.407     Total estimated model params size (MB)\n",
      "/home/augix/miniconda/envs/mamba/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=63` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8471127e797434bbb20a4ed7f263bcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.12751959264278412\n",
      "train_loss: 0.14317581057548523\n",
      "train_loss: 0.11914743483066559\n",
      "train_loss: 0.13077330589294434\n",
      "train_loss: 0.1213809996843338\n",
      "train_loss: 0.12607617676258087\n",
      "train_loss: 0.11274271458387375\n",
      "train_loss: 0.10770411789417267\n",
      "train_loss: 0.10215792804956436\n",
      "train_loss: 0.09805278480052948\n",
      "train_loss: 0.10442468523979187\n",
      "train_loss: 0.10403739660978317\n",
      "train_loss: 0.09111207723617554\n",
      "train_loss: 0.10049887746572495\n",
      "train_loss: 0.097576804459095\n",
      "train_loss: 0.10033366084098816\n",
      "train_loss: 0.09294869005680084\n",
      "train_loss: 0.09833518415689468\n",
      "train_loss: 0.09394189715385437\n",
      "train_loss: 0.09700331091880798\n",
      "train_loss: 0.09154554456472397\n",
      "train_loss: 0.08839244395494461\n",
      "train_loss: 0.0779370367527008\n",
      "train_loss: 0.08739665895700455\n",
      "train_loss: 0.0886666476726532\n",
      "train_loss: 0.08363693207502365\n",
      "train_loss: 0.0731501430273056\n",
      "train_loss: 0.07998725771903992\n",
      "train_loss: 0.07254442572593689\n",
      "train_loss: 0.07517071068286896\n",
      "train_loss: 0.07385583221912384\n",
      "train_loss: 0.07927357405424118\n",
      "train_loss: 0.07644621282815933\n",
      "train_loss: 0.06563364714384079\n",
      "train_loss: 0.06786178052425385\n",
      "train_loss: 0.06946223229169846\n",
      "train_loss: 0.06812546402215958\n",
      "train_loss: 0.06868996471166611\n",
      "train_loss: 0.06656675040721893\n",
      "train_loss: 0.06603678315877914\n",
      "train_loss: 0.07289674878120422\n",
      "train_loss: 0.06865255534648895\n",
      "train_loss: 0.0664869174361229\n",
      "train_loss: 0.06721474230289459\n",
      "train_loss: 0.06376609206199646\n",
      "train_loss: 0.0639793798327446\n",
      "train_loss: 0.05981982499361038\n",
      "train_loss: 0.0654148980975151\n",
      "train_loss: 0.06366011500358582\n",
      "train_loss: 0.0594296008348465\n",
      "train_loss: 0.06527762115001678\n",
      "train_loss: 0.06478633731603622\n",
      "train_loss: 0.0650407001376152\n",
      "train_loss: 0.06558813899755478\n",
      "train_loss: 0.06431899964809418\n",
      "train_loss: 0.06211458891630173\n",
      "train_loss: 0.06261801719665527\n",
      "train_loss: 0.06577190011739731\n",
      "train_loss: 0.06235835328698158\n",
      "train_loss: 0.06438572704792023\n",
      "train_loss: 0.0625431016087532\n",
      "train_loss: 0.05794835463166237\n",
      "train_loss: 0.06273156404495239\n",
      "train_loss: 0.06329130381345749\n",
      "train_loss: 0.058121949434280396\n",
      "train_loss: 0.06022268161177635\n",
      "train_loss: 0.059739015996456146\n",
      "train_loss: 0.06524786353111267\n",
      "train_loss: 0.0640772208571434\n",
      "train_loss: 0.05548075959086418\n",
      "train_loss: 0.06427735835313797\n",
      "train_loss: 0.06682362407445908\n",
      "train_loss: 0.05938231199979782\n",
      "train_loss: 0.06063002347946167\n",
      "train_loss: 0.060886677354574203\n",
      "train_loss: 0.05912647396326065\n",
      "train_loss: 0.057191964238882065\n",
      "train_loss: 0.05821286141872406\n",
      "train_loss: 0.05735890567302704\n",
      "train_loss: 0.05910897254943848\n",
      "train_loss: 0.054968491196632385\n",
      "train_loss: 0.054734159260988235\n",
      "train_loss: 0.0579901784658432\n",
      "train_loss: 0.05931658670306206\n",
      "train_loss: 0.05866542086005211\n",
      "train_loss: 0.0562690794467926\n",
      "train_loss: 0.056065868586301804\n",
      "train_loss: 0.05851759761571884\n",
      "train_loss: 0.05592046305537224\n",
      "train_loss: 0.05831712856888771\n",
      "train_loss: 0.05898113548755646\n",
      "train_loss: 0.05980350077152252\n",
      "train_loss: 0.05702349543571472\n",
      "train_loss: 0.06068501994013786\n",
      "train_loss: 0.052458152174949646\n",
      "train_loss: 0.06022588536143303\n",
      "train_loss: 0.05388036370277405\n",
      "train_loss: 0.058357492089271545\n",
      "train_loss: 0.054001178592443466\n",
      "train_loss: 0.056532423943281174\n",
      "train_loss: 0.054550979286432266\n",
      "train_loss: 0.058678992092609406\n",
      "train_loss: 0.05576702952384949\n",
      "train_loss: 0.05329315364360809\n",
      "train_loss: 0.052800241857767105\n",
      "train_loss: 0.05473124235868454\n",
      "train_loss: 0.05643272399902344\n",
      "train_loss: 0.05644648149609566\n",
      "train_loss: 0.05180371552705765\n",
      "train_loss: 0.05130526050925255\n",
      "train_loss: 0.054584335535764694\n",
      "train_loss: 0.05044819414615631\n",
      "train_loss: 0.05659102648496628\n",
      "train_loss: 0.05453307181596756\n",
      "train_loss: 0.05000033602118492\n",
      "train_loss: 0.05140039324760437\n",
      "train_loss: 0.05707766115665436\n",
      "train_loss: 0.04916633665561676\n",
      "train_loss: 0.051148541271686554\n",
      "train_loss: 0.05761873722076416\n",
      "train_loss: 0.052638132125139236\n",
      "train_loss: 0.05217785760760307\n",
      "train_loss: 0.05592065677046776\n",
      "train_loss: 0.058112796396017075\n",
      "train_loss: 0.053311239928007126\n",
      "train_loss: 0.05810318887233734\n",
      "train_loss: 0.05213748663663864\n",
      "train_loss: 0.054547518491744995\n",
      "train_loss: 0.05604605749249458\n",
      "train_loss: 0.05600879341363907\n",
      "train_loss: 0.053443070501089096\n",
      "train_loss: 0.05239089950919151\n",
      "train_loss: 0.049778398126363754\n",
      "train_loss: 0.05035293102264404\n",
      "train_loss: 0.05473295971751213\n",
      "train_loss: 0.05429694801568985\n",
      "train_loss: 0.05117662623524666\n",
      "train_loss: 0.048185624182224274\n",
      "train_loss: 0.049485206604003906\n",
      "train_loss: 0.04788200929760933\n",
      "train_loss: 0.05454033613204956\n",
      "train_loss: 0.048454564064741135\n",
      "train_loss: 0.05375723913311958\n",
      "train_loss: 0.04861326515674591\n",
      "train_loss: 0.048245783895254135\n",
      "train_loss: 0.05805742368102074\n",
      "train_loss: 0.055438850075006485\n",
      "train_loss: 0.05512061342597008\n",
      "train_loss: 0.05179435387253761\n",
      "train_loss: 0.05149175599217415\n",
      "train_loss: 0.052525606006383896\n",
      "train_loss: 0.055774930864572525\n",
      "train_loss: 0.053727105259895325\n",
      "train_loss: 0.05471044406294823\n",
      "train_loss: 0.054166752845048904\n",
      "train_loss: 0.053619831800460815\n",
      "train_loss: 0.04606156051158905\n",
      "train_loss: 0.052591435611248016\n",
      "train_loss: 0.05190837383270264\n",
      "train_loss: 0.05063564330339432\n",
      "train_loss: 0.052032459527254105\n",
      "train_loss: 0.05006234347820282\n",
      "train_loss: 0.04894484207034111\n",
      "train_loss: 0.04956614971160889\n",
      "train_loss: 0.0491100549697876\n",
      "train_loss: 0.05189471319317818\n",
      "train_loss: 0.04895228520035744\n",
      "train_loss: 0.04957133159041405\n",
      "train_loss: 0.04877709224820137\n",
      "train_loss: 0.050562623888254166\n",
      "train_loss: 0.05083674192428589\n",
      "train_loss: 0.04501757398247719\n",
      "train_loss: 0.05179591849446297\n",
      "train_loss: 0.04810876026749611\n",
      "train_loss: 0.05061968415975571\n",
      "train_loss: 0.053192634135484695\n",
      "train_loss: 0.046224310994148254\n",
      "train_loss: 0.0551157183945179\n",
      "train_loss: 0.050098299980163574\n",
      "train_loss: 0.05227343365550041\n",
      "train_loss: 0.048630572855472565\n",
      "train_loss: 0.053055163472890854\n",
      "train_loss: 0.04936492070555687\n",
      "train_loss: 0.047882381826639175\n",
      "train_loss: 0.048492975533008575\n",
      "train_loss: 0.0479644276201725\n",
      "train_loss: 0.04973955452442169\n",
      "train_loss: 0.04560684412717819\n",
      "train_loss: 0.04866588115692139\n",
      "train_loss: 0.050362955778837204\n",
      "train_loss: 0.051270611584186554\n",
      "train_loss: 0.04842321202158928\n",
      "train_loss: 0.05344996228814125\n",
      "train_loss: 0.0502195730805397\n",
      "train_loss: 0.05034433305263519\n",
      "train_loss: 0.047982357442379\n",
      "train_loss: 0.05226714536547661\n",
      "train_loss: 0.05182301253080368\n",
      "train_loss: 0.05324093997478485\n",
      "train_loss: 0.047809019684791565\n",
      "train_loss: 0.05148759111762047\n",
      "train_loss: 0.05135112628340721\n",
      "train_loss: 0.05090644210577011\n",
      "train_loss: 0.0421144999563694\n",
      "train_loss: 0.04932014271616936\n",
      "train_loss: 0.047460127621889114\n",
      "train_loss: 0.05395358428359032\n",
      "train_loss: 0.044903676956892014\n",
      "train_loss: 0.05259835720062256\n",
      "train_loss: 0.04767930507659912\n",
      "train_loss: 0.045105110853910446\n",
      "train_loss: 0.04773128032684326\n",
      "train_loss: 0.04581599310040474\n",
      "train_loss: 0.05146453529596329\n",
      "train_loss: 0.05003126338124275\n",
      "train_loss: 0.05016513541340828\n",
      "train_loss: 0.04905599355697632\n",
      "train_loss: 0.04936337471008301\n",
      "train_loss: 0.05121007561683655\n",
      "train_loss: 0.05175437778234482\n",
      "train_loss: 0.048507582396268845\n",
      "train_loss: 0.039927903562784195\n",
      "train_loss: 0.04603848606348038\n",
      "train_loss: 0.050213638693094254\n",
      "train_loss: 0.05190116912126541\n",
      "train_loss: 0.04511119797825813\n",
      "train_loss: 0.04234764352440834\n",
      "train_loss: 0.04729677736759186\n",
      "train_loss: 0.05192819982767105\n",
      "train_loss: 0.04705633223056793\n",
      "train_loss: 0.04805668815970421\n",
      "train_loss: 0.04853091016411781\n",
      "train_loss: 0.0431976318359375\n",
      "train_loss: 0.05537310242652893\n",
      "train_loss: 0.04899531975388527\n",
      "train_loss: 0.04850837588310242\n",
      "train_loss: 0.0455545112490654\n",
      "train_loss: 0.04518653824925423\n",
      "train_loss: 0.047189243137836456\n",
      "train_loss: 0.052003294229507446\n",
      "train_loss: 0.05123669281601906\n",
      "train_loss: 0.04929566755890846\n",
      "train_loss: 0.04610868915915489\n",
      "train_loss: 0.04940582066774368\n",
      "train_loss: 0.048409782350063324\n",
      "train_loss: 0.04625794664025307\n",
      "train_loss: 0.048355937004089355\n",
      "train_loss: 0.053361549973487854\n",
      "train_loss: 0.045150987803936005\n",
      "train_loss: 0.04371916502714157\n",
      "train_loss: 0.04991420358419418\n",
      "train_loss: 0.052145786583423615\n",
      "train_loss: 0.051097322255373\n",
      "train_loss: 0.04575611650943756\n",
      "train_loss: 0.04724787175655365\n",
      "train_loss: 0.05208738520741463\n",
      "train_loss: 0.048532165586948395\n",
      "train_loss: 0.05001283064484596\n",
      "train_loss: 0.04953847452998161\n",
      "train_loss: 0.049634408205747604\n",
      "train_loss: 0.04739104211330414\n",
      "train_loss: 0.049080125987529755\n",
      "train_loss: 0.05202016979455948\n",
      "train_loss: 0.04411390423774719\n",
      "train_loss: 0.04634659364819527\n",
      "train_loss: 0.04634340479969978\n",
      "train_loss: 0.047262050211429596\n",
      "train_loss: 0.046712737530469894\n",
      "train_loss: 0.04448549076914787\n",
      "train_loss: 0.04755815118551254\n",
      "train_loss: 0.043384652584791183\n",
      "train_loss: 0.05320681259036064\n",
      "train_loss: 0.056037068367004395\n",
      "train_loss: 0.04797740653157234\n",
      "train_loss: 0.052982304245233536\n",
      "train_loss: 0.05037565529346466\n",
      "train_loss: 0.04713116213679314\n",
      "train_loss: 0.04723423719406128\n",
      "train_loss: 0.043959423899650574\n",
      "train_loss: 0.042768582701683044\n",
      "train_loss: 0.05020307004451752\n",
      "train_loss: 0.04247109591960907\n",
      "train_loss: 0.048134077340364456\n",
      "train_loss: 0.048115458339452744\n",
      "train_loss: 0.046434372663497925\n",
      "train_loss: 0.04492810741066933\n",
      "train_loss: 0.04429175704717636\n",
      "train_loss: 0.048454221338033676\n",
      "train_loss: 0.04183649271726608\n",
      "train_loss: 0.04484803229570389\n",
      "train_loss: 0.04689764976501465\n",
      "train_loss: 0.051542092114686966\n",
      "train_loss: 0.04834981635212898\n",
      "train_loss: 0.04282341152429581\n",
      "train_loss: 0.04948775842785835\n",
      "train_loss: 0.04643518105149269\n",
      "train_loss: 0.046847108751535416\n",
      "train_loss: 0.045878536999225616\n",
      "train_loss: 0.041618652641773224\n",
      "train_loss: 0.05293230339884758\n",
      "train_loss: 0.04740775376558304\n",
      "train_loss: 0.04961438849568367\n",
      "train_loss: 0.0525234155356884\n",
      "train_loss: 0.050146833062171936\n",
      "train_loss: 0.047268446534872055\n",
      "train_loss: 0.04338037595152855\n",
      "train_loss: 0.04771578311920166\n",
      "train_loss: 0.049999430775642395\n",
      "train_loss: 0.04977569729089737\n",
      "train_loss: 0.045834772288799286\n",
      "train_loss: 0.046035297214984894\n",
      "train_loss: 0.047999750822782516\n",
      "train_loss: 0.04932897910475731\n",
      "train_loss: 0.042621564120054245\n",
      "train_loss: 0.051855895668268204\n",
      "train_loss: 0.05102706328034401\n",
      "train_loss: 0.04138154163956642\n",
      "train_loss: 0.0464528389275074\n",
      "train_loss: 0.048899512737989426\n",
      "train_loss: 0.043121084570884705\n",
      "train_loss: 0.051179543137550354\n",
      "train_loss: 0.04720890149474144\n",
      "train_loss: 0.045968540012836456\n",
      "train_loss: 0.04539093002676964\n",
      "train_loss: 0.04839645326137543\n",
      "train_loss: 0.047274570912122726\n",
      "train_loss: 0.04482546076178551\n",
      "train_loss: 0.04883977770805359\n",
      "train_loss: 0.04784522205591202\n",
      "train_loss: 0.04895700141787529\n",
      "train_loss: 0.043845877051353455\n",
      "train_loss: 0.04802997037768364\n",
      "train_loss: 0.044863227754831314\n",
      "train_loss: 0.046098995953798294\n",
      "train_loss: 0.049557752907276154\n",
      "train_loss: 0.04278557375073433\n",
      "train_loss: 0.05244319513440132\n",
      "train_loss: 0.044091738760471344\n",
      "train_loss: 0.0494089350104332\n",
      "train_loss: 0.04792863503098488\n",
      "train_loss: 0.04587608203291893\n",
      "train_loss: 0.047393135726451874\n",
      "train_loss: 0.04863031581044197\n",
      "train_loss: 0.05175936222076416\n",
      "train_loss: 0.04633120074868202\n",
      "train_loss: 0.04670150950551033\n",
      "train_loss: 0.04667051509022713\n",
      "train_loss: 0.052065759897232056\n",
      "train_loss: 0.048724476248025894\n",
      "train_loss: 0.05397018417716026\n",
      "train_loss: 0.046408575028181076\n",
      "train_loss: 0.04894920065999031\n",
      "train_loss: 0.0479341521859169\n",
      "train_loss: 0.049128614366054535\n",
      "train_loss: 0.047702495008707047\n",
      "train_loss: 0.04390990734100342\n",
      "train_loss: 0.04537437483668327\n",
      "train_loss: 0.04485831782221794\n",
      "train_loss: 0.043035224080085754\n",
      "train_loss: 0.044882919639348984\n",
      "train_loss: 0.048570699989795685\n",
      "train_loss: 0.04616963863372803\n",
      "train_loss: 0.04951806738972664\n",
      "train_loss: 0.0487947054207325\n",
      "train_loss: 0.04607752338051796\n",
      "train_loss: 0.042056139558553696\n",
      "train_loss: 0.04361567273736\n",
      "train_loss: 0.043828729540109634\n",
      "train_loss: 0.04880034551024437\n",
      "train_loss: 0.0423777736723423\n",
      "train_loss: 0.04426370561122894\n",
      "train_loss: 0.04580429196357727\n",
      "train_loss: 0.05107469484210014\n",
      "train_loss: 0.04480481520295143\n",
      "train_loss: 0.04296282306313515\n",
      "train_loss: 0.047808192670345306\n",
      "train_loss: 0.05018814280629158\n",
      "train_loss: 0.04734085872769356\n",
      "train_loss: 0.048032667487859726\n",
      "train_loss: 0.04612012580037117\n",
      "train_loss: 0.0508754663169384\n",
      "train_loss: 0.04806580767035484\n",
      "train_loss: 0.0465485118329525\n",
      "train_loss: 0.042829424142837524\n",
      "train_loss: 0.046857453882694244\n",
      "train_loss: 0.041619960218667984\n",
      "train_loss: 0.046776123344898224\n",
      "train_loss: 0.04432569444179535\n",
      "train_loss: 0.044848792254924774\n",
      "train_loss: 0.04607005789875984\n",
      "train_loss: 0.05069054290652275\n",
      "train_loss: 0.04237200692296028\n",
      "train_loss: 0.04505167528986931\n",
      "train_loss: 0.044538602232933044\n",
      "train_loss: 0.046216923743486404\n",
      "train_loss: 0.05236533656716347\n",
      "train_loss: 0.05099187418818474\n",
      "train_loss: 0.050155822187662125\n",
      "train_loss: 0.04822175204753876\n",
      "train_loss: 0.04509258642792702\n",
      "train_loss: 0.04854632169008255\n",
      "train_loss: 0.04505946487188339\n",
      "train_loss: 0.0455661304295063\n",
      "train_loss: 0.04768333584070206\n",
      "train_loss: 0.04717806726694107\n",
      "train_loss: 0.04612618312239647\n",
      "train_loss: 0.04984795302152634\n",
      "train_loss: 0.04352724179625511\n",
      "train_loss: 0.04794866219162941\n",
      "train_loss: 0.04840468242764473\n",
      "train_loss: 0.05082685500383377\n",
      "train_loss: 0.04798898845911026\n",
      "train_loss: 0.04680982977151871\n",
      "train_loss: 0.045586515218019485\n",
      "train_loss: 0.04343835636973381\n",
      "train_loss: 0.0499127060174942\n",
      "train_loss: 0.04728624224662781\n",
      "train_loss: 0.04241006076335907\n",
      "train_loss: 0.04415036737918854\n",
      "train_loss: 0.04742953181266785\n",
      "train_loss: 0.04380973428487778\n",
      "train_loss: 0.04930385574698448\n",
      "train_loss: 0.046107999980449677\n",
      "train_loss: 0.049056485295295715\n",
      "train_loss: 0.049482449889183044\n",
      "train_loss: 0.04232906177639961\n",
      "train_loss: 0.04747336730360985\n",
      "train_loss: 0.04160637781023979\n",
      "train_loss: 0.05115489289164543\n",
      "train_loss: 0.0462033674120903\n",
      "train_loss: 0.04546617716550827\n",
      "train_loss: 0.049765001982450485\n",
      "train_loss: 0.05257707089185715\n",
      "train_loss: 0.04155847802758217\n",
      "train_loss: 0.04508035257458687\n",
      "train_loss: 0.04452073574066162\n",
      "train_loss: 0.045134685933589935\n",
      "train_loss: 0.04632693901658058\n",
      "train_loss: 0.04761858657002449\n",
      "train_loss: 0.04823915287852287\n",
      "train_loss: 0.050468046218156815\n",
      "train_loss: 0.05219469219446182\n",
      "train_loss: 0.04468277469277382\n",
      "train_loss: 0.044155869632959366\n",
      "train_loss: 0.04371728003025055\n",
      "train_loss: 0.055428240448236465\n",
      "train_loss: 0.04749835282564163\n",
      "train_loss: 0.04686020687222481\n",
      "train_loss: 0.045122310519218445\n",
      "train_loss: 0.048163093626499176\n",
      "train_loss: 0.04196557030081749\n",
      "train_loss: 0.04774076119065285\n",
      "train_loss: 0.049075156450271606\n",
      "train_loss: 0.04278769716620445\n",
      "train_loss: 0.04704537242650986\n",
      "train_loss: 0.045500658452510834\n",
      "train_loss: 0.04661968722939491\n",
      "train_loss: 0.04489443078637123\n",
      "train_loss: 0.043114934116601944\n",
      "train_loss: 0.04210522770881653\n",
      "train_loss: 0.04734368994832039\n",
      "train_loss: 0.04398636892437935\n",
      "train_loss: 0.04254058003425598\n",
      "train_loss: 0.04785787686705589\n",
      "train_loss: 0.04586159437894821\n",
      "train_loss: 0.050074998289346695\n",
      "train_loss: 0.0462222620844841\n",
      "train_loss: 0.04607147350907326\n",
      "train_loss: 0.047100987285375595\n",
      "train_loss: 0.04737741872668266\n",
      "train_loss: 0.05084357038140297\n",
      "train_loss: 0.04100410267710686\n",
      "train_loss: 0.045621778815984726\n",
      "train_loss: 0.04588185250759125\n",
      "train_loss: 0.04848482087254524\n",
      "train_loss: 0.044670503586530685\n",
      "train_loss: 0.04230006784200668\n",
      "train_loss: 0.04679330438375473\n",
      "train_loss: 0.045938778668642044\n",
      "train_loss: 0.04138781130313873\n",
      "train_loss: 0.0447058379650116\n",
      "train_loss: 0.04637867957353592\n",
      "train_loss: 0.038009267300367355\n",
      "train_loss: 0.042928680777549744\n",
      "train_loss: 0.04830460995435715\n",
      "train_loss: 0.05214254930615425\n",
      "train_loss: 0.04574429988861084\n",
      "train_loss: 0.04402315616607666\n",
      "train_loss: 0.04230784252285957\n",
      "train_loss: 0.041815776377916336\n",
      "train_loss: 0.04386824369430542\n",
      "train_loss: 0.042095478624105453\n",
      "train_loss: 0.04987581446766853\n",
      "train_loss: 0.04790301248431206\n",
      "train_loss: 0.049979787319898605\n",
      "train_loss: 0.04521877318620682\n",
      "train_loss: 0.04105560854077339\n",
      "train_loss: 0.04754262790083885\n",
      "train_loss: 0.04834248498082161\n",
      "train_loss: 0.04819158464670181\n",
      "train_loss: 0.04773088917136192\n",
      "train_loss: 0.04772891849279404\n",
      "train_loss: 0.04720620438456535\n",
      "train_loss: 0.044553231447935104\n",
      "train_loss: 0.04902706295251846\n",
      "train_loss: 0.04597344622015953\n",
      "train_loss: 0.05301732197403908\n",
      "train_loss: 0.04292531684041023\n",
      "train_loss: 0.04721686244010925\n",
      "train_loss: 0.04773208871483803\n",
      "train_loss: 0.04816501960158348\n",
      "train_loss: 0.04611920565366745\n",
      "train_loss: 0.04552771896123886\n",
      "train_loss: 0.047455936670303345\n",
      "train_loss: 0.0459870882332325\n",
      "train_loss: 0.050424233078956604\n",
      "train_loss: 0.04660898819565773\n",
      "train_loss: 0.049733716994524\n",
      "train_loss: 0.04563739895820618\n",
      "train_loss: 0.04451286047697067\n",
      "train_loss: 0.043868374079465866\n",
      "train_loss: 0.045903366059064865\n",
      "train_loss: 0.043526459485292435\n",
      "train_loss: 0.04960858076810837\n",
      "train_loss: 0.04431091248989105\n",
      "train_loss: 0.0428970642387867\n",
      "train_loss: 0.0471283458173275\n",
      "train_loss: 0.0484614260494709\n",
      "train_loss: 0.04272890090942383\n",
      "train_loss: 0.046470899134874344\n",
      "train_loss: 0.04440058395266533\n",
      "train_loss: 0.044423285871744156\n",
      "train_loss: 0.041503239423036575\n",
      "train_loss: 0.04887264594435692\n",
      "train_loss: 0.049623601138591766\n",
      "train_loss: 0.043252598494291306\n",
      "train_loss: 0.05068497732281685\n",
      "train_loss: 0.043150003999471664\n",
      "train_loss: 0.03771089017391205\n",
      "train_loss: 0.051615141332149506\n",
      "train_loss: 0.051081880927085876\n",
      "train_loss: 0.04560285434126854\n",
      "train_loss: 0.05264783278107643\n",
      "train_loss: 0.04677668958902359\n",
      "train_loss: 0.048260729759931564\n",
      "train_loss: 0.0409882515668869\n",
      "train_loss: 0.04326803609728813\n",
      "train_loss: 0.047700874507427216\n",
      "train_loss: 0.046780478209257126\n",
      "train_loss: 0.04438025876879692\n",
      "train_loss: 0.04431438818573952\n",
      "train_loss: 0.043138206005096436\n",
      "train_loss: 0.04588055983185768\n",
      "train_loss: 0.04727403447031975\n",
      "train_loss: 0.04588187485933304\n",
      "train_loss: 0.04665754735469818\n",
      "train_loss: 0.04067869856953621\n",
      "train_loss: 0.04025477543473244\n",
      "train_loss: 0.04227663576602936\n",
      "train_loss: 0.0474848635494709\n",
      "train_loss: 0.04849272593855858\n",
      "train_loss: 0.041896604001522064\n",
      "train_loss: 0.040580566972494125\n",
      "train_loss: 0.044856470078229904\n",
      "train_loss: 0.046877115964889526\n",
      "train_loss: 0.04613490030169487\n",
      "train_loss: 0.04434327781200409\n",
      "train_loss: 0.043306756764650345\n",
      "train_loss: 0.0508398711681366\n",
      "train_loss: 0.03983321413397789\n",
      "train_loss: 0.044601552188396454\n",
      "train_loss: 0.043705154210329056\n",
      "train_loss: 0.05088760331273079\n",
      "train_loss: 0.04935488477349281\n",
      "train_loss: 0.05520930513739586\n",
      "train_loss: 0.04593164473772049\n",
      "train_loss: 0.04867694899439812\n",
      "train_loss: 0.043369777500629425\n",
      "train_loss: 0.04598883166909218\n",
      "train_loss: 0.04839200899004936\n",
      "train_loss: 0.05060555785894394\n",
      "train_loss: 0.0449497252702713\n",
      "train_loss: 0.04511005058884621\n",
      "train_loss: 0.039721645414829254\n",
      "train_loss: 0.04672829061746597\n",
      "train_loss: 0.04405658319592476\n",
      "train_loss: 0.037614692002534866\n",
      "train_loss: 0.04575023800134659\n",
      "train_loss: 0.04434003680944443\n",
      "train_loss: 0.04837184399366379\n",
      "train_loss: 0.049692220985889435\n",
      "train_loss: 0.04298286885023117\n",
      "train_loss: 0.044229913502931595\n",
      "train_loss: 0.0495247058570385\n",
      "train_loss: 0.04180660843849182\n",
      "train_loss: 0.04235789179801941\n",
      "train_loss: 0.04664604738354683\n",
      "train_loss: 0.044797878712415695\n",
      "train_loss: 0.048556141555309296\n",
      "train_loss: 0.04637691006064415\n",
      "train_loss: 0.05176253244280815\n",
      "train_loss: 0.048902735114097595\n",
      "train_loss: 0.047203101217746735\n",
      "train_loss: 0.046048473566770554\n",
      "train_loss: 0.04792708531022072\n",
      "train_loss: 0.047245606780052185\n",
      "train_loss: 0.0443853922188282\n",
      "train_loss: 0.04263481870293617\n",
      "train_loss: 0.047456756234169006\n",
      "train_loss: 0.03996362164616585\n",
      "train_loss: 0.04635666683316231\n",
      "train_loss: 0.03956589102745056\n",
      "train_loss: 0.039911672472953796\n",
      "train_loss: 0.04072566702961922\n",
      "train_loss: 0.042206160724163055\n",
      "train_loss: 0.04360797256231308\n",
      "train_loss: 0.044521402567625046\n",
      "train_loss: 0.04078415036201477\n",
      "train_loss: 0.04205017536878586\n",
      "train_loss: 0.04410387575626373\n",
      "train_loss: 0.041484151035547256\n",
      "train_loss: 0.052839599549770355\n",
      "train_loss: 0.050272390246391296\n",
      "train_loss: 0.05106888711452484\n",
      "train_loss: 0.04638347774744034\n",
      "train_loss: 0.05112871900200844\n",
      "train_loss: 0.041305530816316605\n",
      "train_loss: 0.04710278660058975\n",
      "train_loss: 0.04660351946949959\n",
      "train_loss: 0.03964104503393173\n",
      "train_loss: 0.044154778122901917\n",
      "train_loss: 0.03937222808599472\n",
      "train_loss: 0.044759564101696014\n",
      "train_loss: 0.04352366924285889\n",
      "train_loss: 0.04517151415348053\n",
      "train_loss: 0.04692023992538452\n",
      "train_loss: 0.04317433387041092\n",
      "train_loss: 0.04538881406188011\n",
      "train_loss: 0.044435374438762665\n",
      "train_loss: 0.04503994435071945\n",
      "train_loss: 0.041545335203409195\n",
      "train_loss: 0.04229463264346123\n",
      "train_loss: 0.04765800014138222\n",
      "train_loss: 0.0491437092423439\n",
      "train_loss: 0.04408568516373634\n",
      "train_loss: 0.04520036280155182\n",
      "train_loss: 0.04502466693520546\n",
      "train_loss: 0.04339887201786041\n",
      "train_loss: 0.04620378836989403\n",
      "train_loss: 0.048399779945611954\n",
      "train_loss: 0.04264279082417488\n",
      "train_loss: 0.04566386342048645\n",
      "train_loss: 0.04334964603185654\n",
      "train_loss: 0.04292222484946251\n",
      "train_loss: 0.048030223697423935\n",
      "train_loss: 0.04335705190896988\n",
      "train_loss: 0.041038770228624344\n",
      "train_loss: 0.04750623553991318\n",
      "train_loss: 0.048840124160051346\n",
      "train_loss: 0.04222313314676285\n",
      "train_loss: 0.04401601105928421\n",
      "train_loss: 0.04766623675823212\n",
      "train_loss: 0.043961524963378906\n",
      "train_loss: 0.04577913135290146\n",
      "train_loss: 0.04181980341672897\n",
      "train_loss: 0.042660463601350784\n",
      "train_loss: 0.04109867289662361\n",
      "train_loss: 0.04258160665631294\n",
      "train_loss: 0.04596097394824028\n",
      "train_loss: 0.04896249994635582\n",
      "train_loss: 0.04199685901403427\n",
      "train_loss: 0.047818075865507126\n",
      "train_loss: 0.04094676673412323\n",
      "train_loss: 0.045065946877002716\n",
      "train_loss: 0.04222086817026138\n",
      "train_loss: 0.046291496604681015\n",
      "train_loss: 0.04038352519273758\n",
      "train_loss: 0.04434249922633171\n",
      "train_loss: 0.04251890629529953\n",
      "train_loss: 0.04340055584907532\n",
      "train_loss: 0.04253968968987465\n",
      "train_loss: 0.04408038407564163\n",
      "train_loss: 0.03913091868162155\n",
      "train_loss: 0.04817039147019386\n",
      "train_loss: 0.0430159866809845\n",
      "train_loss: 0.04670882225036621\n",
      "train_loss: 0.04998054727911949\n",
      "train_loss: 0.04637441784143448\n",
      "train_loss: 0.04754495620727539\n",
      "train_loss: 0.04450664296746254\n",
      "train_loss: 0.045420099049806595\n",
      "train_loss: 0.05168340355157852\n",
      "train_loss: 0.04239950701594353\n",
      "train_loss: 0.05040658265352249\n",
      "train_loss: 0.04638086259365082\n",
      "train_loss: 0.046176131814718246\n",
      "train_loss: 0.048713795840740204\n",
      "train_loss: 0.04271876811981201\n",
      "train_loss: 0.04798847809433937\n",
      "train_loss: 0.046915024518966675\n",
      "train_loss: 0.04490348696708679\n",
      "train_loss: 0.0517229326069355\n",
      "train_loss: 0.04839704558253288\n",
      "train_loss: 0.0439547523856163\n",
      "train_loss: 0.04746861383318901\n",
      "train_loss: 0.04415857419371605\n",
      "train_loss: 0.04445195570588112\n",
      "train_loss: 0.044347867369651794\n",
      "train_loss: 0.043575748801231384\n",
      "train_loss: 0.042402587831020355\n",
      "train_loss: 0.04830443859100342\n",
      "train_loss: 0.041199974715709686\n",
      "train_loss: 0.04368159547448158\n",
      "train_loss: 0.04248395189642906\n",
      "train_loss: 0.0455692820250988\n",
      "train_loss: 0.041681598871946335\n",
      "train_loss: 0.04120226204395294\n",
      "train_loss: 0.0453052893280983\n",
      "train_loss: 0.0424162894487381\n",
      "train_loss: 0.04444529116153717\n",
      "train_loss: 0.044408466666936874\n",
      "train_loss: 0.04464404284954071\n",
      "train_loss: 0.046465564519166946\n",
      "train_loss: 0.049425844103097916\n",
      "train_loss: 0.047597311437129974\n",
      "train_loss: 0.04343624785542488\n",
      "train_loss: 0.043646857142448425\n",
      "train_loss: 0.042735546827316284\n",
      "train_loss: 0.04364553838968277\n",
      "train_loss: 0.04403037950396538\n",
      "train_loss: 0.04797899350523949\n",
      "train_loss: 0.04024159535765648\n",
      "train_loss: 0.04268082603812218\n",
      "train_loss: 0.04206738620996475\n",
      "train_loss: 0.048172399401664734\n",
      "train_loss: 0.048157915472984314\n",
      "train_loss: 0.040792372077703476\n",
      "train_loss: 0.046011097729206085\n",
      "train_loss: 0.04283864051103592\n",
      "train_loss: 0.043784402310848236\n",
      "train_loss: 0.04686281085014343\n",
      "train_loss: 0.04641954228281975\n",
      "train_loss: 0.048610735684633255\n",
      "train_loss: 0.047676943242549896\n",
      "train_loss: 0.04108767583966255\n",
      "train_loss: 0.04376966878771782\n",
      "train_loss: 0.03930763155221939\n",
      "train_loss: 0.043596237897872925\n",
      "train_loss: 0.046753890812397\n",
      "train_loss: 0.04737821966409683\n",
      "train_loss: 0.05045539513230324\n",
      "train_loss: 0.049079593271017075\n",
      "train_loss: 0.04418664053082466\n",
      "train_loss: 0.04432906210422516\n",
      "train_loss: 0.05208373814821243\n",
      "train_loss: 0.04336869716644287\n",
      "train_loss: 0.044198282063007355\n",
      "train_loss: 0.045205798000097275\n",
      "train_loss: 0.04154442623257637\n",
      "train_loss: 0.05093599855899811\n",
      "train_loss: 0.044298287481069565\n",
      "train_loss: 0.04602661728858948\n",
      "train_loss: 0.04091651365160942\n",
      "train_loss: 0.04582110047340393\n",
      "train_loss: 0.04856206849217415\n",
      "train_loss: 0.044178836047649384\n",
      "train_loss: 0.048791058361530304\n",
      "train_loss: 0.042773302644491196\n",
      "train_loss: 0.04975522309541702\n",
      "train_loss: 0.04357392340898514\n",
      "train_loss: 0.04807008057832718\n",
      "train_loss: 0.04145721346139908\n",
      "train_loss: 0.04328176751732826\n",
      "train_loss: 0.04232973977923393\n",
      "train_loss: 0.046202514320611954\n",
      "train_loss: 0.045061688870191574\n",
      "train_loss: 0.04902104660868645\n",
      "train_loss: 0.04394982382655144\n",
      "train_loss: 0.0444447360932827\n",
      "train_loss: 0.040687840431928635\n",
      "train_loss: 0.04943675175309181\n",
      "train_loss: 0.0457879938185215\n",
      "train_loss: 0.046260617673397064\n",
      "train_loss: 0.04612025246024132\n",
      "train_loss: 0.04670581966638565\n",
      "train_loss: 0.04147614538669586\n",
      "train_loss: 0.04776337742805481\n",
      "train_loss: 0.04132574424147606\n",
      "train_loss: 0.047282204031944275\n",
      "train_loss: 0.04495932161808014\n",
      "train_loss: 0.047070614993572235\n",
      "train_loss: 0.04329201579093933\n",
      "train_loss: 0.04695649817585945\n",
      "train_loss: 0.046391796320676804\n",
      "train_loss: 0.042086560279130936\n",
      "train_loss: 0.04329374432563782\n",
      "train_loss: 0.045889366418123245\n",
      "train_loss: 0.0398511067032814\n",
      "train_loss: 0.04548490047454834\n",
      "train_loss: 0.04609673097729683\n",
      "train_loss: 0.041108012199401855\n",
      "train_loss: 0.045864563435316086\n",
      "train_loss: 0.04538754001259804\n",
      "train_loss: 0.04946304112672806\n",
      "train_loss: 0.039771754294633865\n",
      "train_loss: 0.0480959489941597\n",
      "train_loss: 0.04585503414273262\n",
      "train_loss: 0.04827069118618965\n",
      "train_loss: 0.044235870242118835\n",
      "train_loss: 0.0427253395318985\n",
      "train_loss: 0.04273238033056259\n",
      "train_loss: 0.04357859492301941\n",
      "train_loss: 0.04186050221323967\n",
      "train_loss: 0.044616151601076126\n",
      "train_loss: 0.053396448493003845\n",
      "train_loss: 0.043691959232091904\n",
      "train_loss: 0.04430416598916054\n",
      "train_loss: 0.04572019353508949\n",
      "train_loss: 0.04425888508558273\n",
      "train_loss: 0.04679079353809357\n",
      "train_loss: 0.04500037804245949\n",
      "train_loss: 0.040739234536886215\n",
      "train_loss: 0.04223734885454178\n",
      "train_loss: 0.041876498609781265\n",
      "train_loss: 0.04711567610502243\n",
      "train_loss: 0.047043293714523315\n",
      "train_loss: 0.05125945433974266\n",
      "train_loss: 0.047204405069351196\n",
      "train_loss: 0.04449192434549332\n",
      "train_loss: 0.043530240654945374\n",
      "train_loss: 0.04572310671210289\n",
      "train_loss: 0.04291388764977455\n",
      "train_loss: 0.04128909856081009\n",
      "train_loss: 0.04552333056926727\n",
      "train_loss: 0.045439835637807846\n",
      "train_loss: 0.04022026062011719\n",
      "train_loss: 0.04721467196941376\n",
      "train_loss: 0.0408690981566906\n",
      "train_loss: 0.04273918643593788\n",
      "train_loss: 0.043710313737392426\n",
      "train_loss: 0.04598548263311386\n",
      "train_loss: 0.04145945608615875\n",
      "train_loss: 0.04726729169487953\n",
      "train_loss: 0.05025704950094223\n",
      "train_loss: 0.038585223257541656\n",
      "train_loss: 0.04044068232178688\n",
      "train_loss: 0.0450492762029171\n",
      "train_loss: 0.045357439666986465\n",
      "train_loss: 0.041925098747015\n",
      "train_loss: 0.04251658916473389\n",
      "train_loss: 0.042707234621047974\n",
      "train_loss: 0.04786383733153343\n",
      "train_loss: 0.039039913564920425\n",
      "train_loss: 0.04466306418180466\n",
      "train_loss: 0.044768624007701874\n",
      "train_loss: 0.047750793397426605\n",
      "train_loss: 0.04295683652162552\n",
      "train_loss: 0.04719242826104164\n",
      "train_loss: 0.04762233421206474\n",
      "train_loss: 0.041400615125894547\n",
      "train_loss: 0.04754747450351715\n",
      "train_loss: 0.04571448266506195\n",
      "train_loss: 0.03819332271814346\n",
      "train_loss: 0.04685226082801819\n",
      "train_loss: 0.04488183557987213\n",
      "train_loss: 0.04421434924006462\n",
      "train_loss: 0.04244491457939148\n",
      "train_loss: 0.04460405558347702\n",
      "train_loss: 0.04324863478541374\n",
      "train_loss: 0.04641151428222656\n",
      "train_loss: 0.049319926649332047\n",
      "train_loss: 0.043665073812007904\n",
      "train_loss: 0.04574824124574661\n",
      "train_loss: 0.04803762584924698\n",
      "train_loss: 0.042229942977428436\n",
      "train_loss: 0.044021669775247574\n",
      "train_loss: 0.04345210641622543\n",
      "train_loss: 0.04218403249979019\n",
      "train_loss: 0.04420388489961624\n",
      "train_loss: 0.04591420292854309\n",
      "train_loss: 0.048343878239393234\n",
      "train_loss: 0.05118821561336517\n",
      "train_loss: 0.04965243488550186\n",
      "train_loss: 0.04105573147535324\n",
      "train_loss: 0.04065876081585884\n",
      "train_loss: 0.03777569159865379\n",
      "train_loss: 0.04055451601743698\n",
      "train_loss: 0.04627344384789467\n",
      "train_loss: 0.04293398931622505\n",
      "train_loss: 0.045448120683431625\n",
      "train_loss: 0.04321494325995445\n",
      "train_loss: 0.055426888167858124\n",
      "train_loss: 0.04386250302195549\n",
      "train_loss: 0.04489380866289139\n",
      "train_loss: 0.042810507118701935\n",
      "train_loss: 0.03983123600482941\n",
      "train_loss: 0.04666338115930557\n",
      "train_loss: 0.049638260155916214\n",
      "train_loss: 0.043695010244846344\n",
      "train_loss: 0.047082703560590744\n",
      "train_loss: 0.04711110517382622\n",
      "train_loss: 0.040946681052446365\n",
      "train_loss: 0.04273636266589165\n",
      "train_loss: 0.04680518060922623\n",
      "train_loss: 0.04903649538755417\n",
      "train_loss: 0.0391499400138855\n",
      "train_loss: 0.04592113196849823\n",
      "train_loss: 0.04399624466896057\n",
      "train_loss: 0.04396381974220276\n",
      "train_loss: 0.046271342784166336\n",
      "train_loss: 0.04186531901359558\n",
      "train_loss: 0.04334135726094246\n",
      "train_loss: 0.0409015491604805\n",
      "train_loss: 0.048863887786865234\n",
      "train_loss: 0.04378362372517586\n",
      "train_loss: 0.04031119868159294\n",
      "train_loss: 0.047305379062891006\n",
      "train_loss: 0.046547479927539825\n",
      "train_loss: 0.04252304881811142\n",
      "train_loss: 0.03937147930264473\n",
      "train_loss: 0.04373956099152565\n",
      "train_loss: 0.04511948302388191\n",
      "train_loss: 0.045297279953956604\n",
      "train_loss: 0.05025458708405495\n",
      "train_loss: 0.04457038640975952\n",
      "train_loss: 0.04474335163831711\n",
      "train_loss: 0.040446504950523376\n",
      "train_loss: 0.04985237494111061\n",
      "train_loss: 0.04723795875906944\n",
      "train_loss: 0.04703840985894203\n",
      "train_loss: 0.043446872383356094\n",
      "train_loss: 0.040790777653455734\n",
      "train_loss: 0.04479142650961876\n",
      "train_loss: 0.04169229418039322\n",
      "train_loss: 0.04217970371246338\n",
      "train_loss: 0.0427076630294323\n",
      "train_loss: 0.041474588215351105\n",
      "train_loss: 0.04399712011218071\n",
      "train_loss: 0.047618601471185684\n",
      "train_loss: 0.05034232512116432\n",
      "train_loss: 0.043759822845458984\n",
      "train_loss: 0.04124797135591507\n",
      "train_loss: 0.04101866856217384\n",
      "train_loss: 0.046198293566703796\n",
      "train_loss: 0.03879808261990547\n",
      "train_loss: 0.04646867513656616\n",
      "train_loss: 0.04931747540831566\n",
      "train_loss: 0.05036136507987976\n",
      "train_loss: 0.04936903342604637\n",
      "train_loss: 0.042803071439266205\n",
      "train_loss: 0.043399628251791\n",
      "train_loss: 0.04120755195617676\n",
      "train_loss: 0.04561138153076172\n",
      "train_loss: 0.03565239906311035\n",
      "train_loss: 0.045738935470581055\n",
      "train_loss: 0.043694447726011276\n",
      "train_loss: 0.043452437967061996\n",
      "train_loss: 0.04581316560506821\n",
      "train_loss: 0.04358299449086189\n",
      "train_loss: 0.04420642554759979\n",
      "train_loss: 0.04330926015973091\n",
      "train_loss: 0.04126644879579544\n",
      "train_loss: 0.045834098011255264\n",
      "train_loss: 0.048381220549345016\n",
      "train_loss: 0.04489625245332718\n",
      "train_loss: 0.03742785379290581\n",
      "train_loss: 0.04464096948504448\n",
      "train_loss: 0.042118266224861145\n",
      "train_loss: 0.04915594309568405\n",
      "train_loss: 0.048264406621456146\n",
      "train_loss: 0.04120289906859398\n",
      "train_loss: 0.03710109367966652\n",
      "train_loss: 0.0413886234164238\n",
      "train_loss: 0.047005098313093185\n",
      "train_loss: 0.0456668883562088\n",
      "train_loss: 0.042634040117263794\n",
      "train_loss: 0.04219752922654152\n",
      "train_loss: 0.04136713966727257\n",
      "train_loss: 0.04452967643737793\n",
      "train_loss: 0.038639891892671585\n",
      "train_loss: 0.04649704322218895\n",
      "train_loss: 0.04350481927394867\n",
      "train_loss: 0.04074519872665405\n",
      "train_loss: 0.04504288360476494\n",
      "train_loss: 0.04604768753051758\n",
      "train_loss: 0.04209193214774132\n",
      "train_loss: 0.04584462568163872\n",
      "train_loss: 0.042840924113988876\n",
      "train_loss: 0.0456823855638504\n",
      "train_loss: 0.045657236129045486\n",
      "train_loss: 0.04843367263674736\n",
      "train_loss: 0.039217621088027954\n",
      "train_loss: 0.04472360759973526\n",
      "train_loss: 0.04028346762061119\n",
      "train_loss: 0.04551520571112633\n",
      "train_loss: 0.04779449850320816\n",
      "train_loss: 0.05016302317380905\n",
      "train_loss: 0.044500257819890976\n",
      "train_loss: 0.04597341641783714\n",
      "train_loss: 0.04183405265212059\n",
      "train_loss: 0.04553684964776039\n",
      "train_loss: 0.04421752691268921\n",
      "train_loss: 0.046568188816308975\n",
      "train_loss: 0.047335751354694366\n",
      "train_loss: 0.041790056973695755\n",
      "train_loss: 0.043807126581668854\n",
      "train_loss: 0.04147045686841011\n",
      "train_loss: 0.04145342856645584\n",
      "train_loss: 0.0409744456410408\n",
      "train_loss: 0.044840890914201736\n",
      "train_loss: 0.04729028046131134\n",
      "train_loss: 0.04768511652946472\n",
      "train_loss: 0.0454142726957798\n",
      "train_loss: 0.0482235886156559\n",
      "train_loss: 0.0437869094312191\n",
      "train_loss: 0.0483442023396492\n",
      "train_loss: 0.04705032333731651\n",
      "train_loss: 0.04005266726016998\n",
      "train_loss: 0.03761681541800499\n",
      "train_loss: 0.04189576953649521\n",
      "train_loss: 0.05060074105858803\n",
      "train_loss: 0.03937973082065582\n",
      "train_loss: 0.042317286133766174\n",
      "train_loss: 0.04804885387420654\n",
      "train_loss: 0.04539676383137703\n",
      "train_loss: 0.03966189920902252\n",
      "train_loss: 0.04500347003340721\n",
      "train_loss: 0.0479140505194664\n",
      "train_loss: 0.045998021960258484\n",
      "train_loss: 0.05010927841067314\n",
      "train_loss: 0.040521491318941116\n",
      "train_loss: 0.050882499665021896\n",
      "train_loss: 0.04529089108109474\n",
      "train_loss: 0.0439680740237236\n",
      "train_loss: 0.04724922776222229\n",
      "train_loss: 0.043297719210386276\n",
      "train_loss: 0.042126718908548355\n",
      "train_loss: 0.04254845157265663\n",
      "train_loss: 0.040256962180137634\n",
      "train_loss: 0.0457228347659111\n",
      "train_loss: 0.04317628592252731\n",
      "train_loss: 0.05138864368200302\n",
      "train_loss: 0.03917320817708969\n",
      "train_loss: 0.0426187738776207\n",
      "train_loss: 0.044651489704847336\n",
      "train_loss: 0.03840946778655052\n",
      "train_loss: 0.0486544594168663\n",
      "train_loss: 0.04686952382326126\n",
      "train_loss: 0.042899925261735916\n",
      "train_loss: 0.04389457777142525\n",
      "train_loss: 0.05062364414334297\n",
      "train_loss: 0.04424198344349861\n",
      "train_loss: 0.04258633404970169\n",
      "train_loss: 0.04445157200098038\n",
      "train_loss: 0.044370755553245544\n",
      "train_loss: 0.04298047721385956\n",
      "train_loss: 0.0442684143781662\n",
      "train_loss: 0.04275995120406151\n",
      "train_loss: 0.04390968009829521\n",
      "train_loss: 0.03934766724705696\n",
      "train_loss: 0.0466393381357193\n",
      "train_loss: 0.04523840546607971\n",
      "train_loss: 0.0448613166809082\n",
      "train_loss: 0.04719119891524315\n",
      "train_loss: 0.044396352022886276\n",
      "train_loss: 0.050641145557165146\n",
      "train_loss: 0.043056488037109375\n",
      "train_loss: 0.039371538907289505\n",
      "train_loss: 0.04971225932240486\n",
      "train_loss: 0.04463070631027222\n",
      "train_loss: 0.04283268004655838\n",
      "train_loss: 0.043222833424806595\n",
      "train_loss: 0.03992222249507904\n",
      "train_loss: 0.0482882559299469\n",
      "train_loss: 0.04697570949792862\n",
      "train_loss: 0.04180767014622688\n",
      "train_loss: 0.04910276457667351\n",
      "train_loss: 0.04151913896203041\n",
      "train_loss: 0.04442756250500679\n",
      "train_loss: 0.04820816591382027\n",
      "train_loss: 0.045335423201322556\n",
      "train_loss: 0.03905155509710312\n",
      "train_loss: 0.04005502909421921\n",
      "train_loss: 0.04452293738722801\n",
      "train_loss: 0.040106285363435745\n",
      "train_loss: 0.04559461399912834\n",
      "train_loss: 0.04075554013252258\n",
      "train_loss: 0.04283790662884712\n",
      "train_loss: 0.04095182567834854\n",
      "train_loss: 0.05043761804699898\n",
      "train_loss: 0.04725942388176918\n",
      "train_loss: 0.040410369634628296\n",
      "train_loss: 0.04438348487019539\n",
      "train_loss: 0.04476730152964592\n",
      "train_loss: 0.042615342885255814\n",
      "train_loss: 0.03951212018728256\n",
      "train_loss: 0.043874699622392654\n",
      "train_loss: 0.045345403254032135\n",
      "train_loss: 0.04263809695839882\n",
      "train_loss: 0.03872118145227432\n",
      "train_loss: 0.043667182326316833\n",
      "train_loss: 0.04475349187850952\n",
      "train_loss: 0.04083665460348129\n",
      "train_loss: 0.04533359408378601\n",
      "train_loss: 0.04226969555020332\n",
      "train_loss: 0.046609584242105484\n",
      "train_loss: 0.04293866828083992\n",
      "train_loss: 0.043373383581638336\n",
      "train_loss: 0.04617587476968765\n",
      "train_loss: 0.048030413687229156\n",
      "train_loss: 0.045691780745983124\n",
      "train_loss: 0.04355742037296295\n",
      "train_loss: 0.04633624106645584\n",
      "train_loss: 0.046811673790216446\n",
      "train_loss: 0.04691701382398605\n",
      "train_loss: 0.04408039152622223\n",
      "train_loss: 0.047665730118751526\n",
      "train_loss: 0.04197978973388672\n",
      "train_loss: 0.04538051038980484\n",
      "train_loss: 0.05414341762661934\n",
      "train_loss: 0.050498202443122864\n",
      "train_loss: 0.050215426832437515\n",
      "train_loss: 0.043873149901628494\n",
      "train_loss: 0.04218457639217377\n",
      "train_loss: 0.035859059542417526\n",
      "train_loss: 0.046730320900678635\n",
      "train_loss: 0.04238111525774002\n",
      "train_loss: 0.04361240938305855\n",
      "train_loss: 0.040194302797317505\n",
      "train_loss: 0.044400010257959366\n",
      "train_loss: 0.04314890503883362\n",
      "train_loss: 0.03973456844687462\n",
      "train_loss: 0.040391307324171066\n",
      "train_loss: 0.04145029932260513\n",
      "train_loss: 0.04921611398458481\n",
      "train_loss: 0.040537092834711075\n",
      "train_loss: 0.04620113596320152\n",
      "train_loss: 0.04189135134220123\n",
      "train_loss: 0.04530617594718933\n",
      "train_loss: 0.03965244069695473\n",
      "train_loss: 0.04357820376753807\n",
      "train_loss: 0.045018840581178665\n",
      "train_loss: 0.04046054556965828\n",
      "train_loss: 0.04162584990262985\n",
      "train_loss: 0.038063038140535355\n",
      "train_loss: 0.038563162088394165\n",
      "train_loss: 0.045134689658880234\n",
      "train_loss: 0.04114995524287224\n",
      "train_loss: 0.04232385754585266\n",
      "train_loss: 0.0435931421816349\n",
      "train_loss: 0.042890723794698715\n",
      "train_loss: 0.035402558743953705\n",
      "train_loss: 0.041624389588832855\n",
      "train_loss: 0.043755337595939636\n",
      "train_loss: 0.04421735554933548\n",
      "train_loss: 0.04125840216875076\n",
      "train_loss: 0.04740939289331436\n",
      "train_loss: 0.0396028496325016\n",
      "train_loss: 0.0467073954641819\n",
      "train_loss: 0.045783501118421555\n",
      "train_loss: 0.04409356042742729\n",
      "train_loss: 0.04415043815970421\n",
      "train_loss: 0.04313017427921295\n",
      "train_loss: 0.041408028453588486\n",
      "train_loss: 0.04268240928649902\n",
      "train_loss: 0.04665227606892586\n",
      "train_loss: 0.04477164149284363\n",
      "train_loss: 0.04404771327972412\n",
      "train_loss: 0.04035191237926483\n",
      "train_loss: 0.04458988830447197\n",
      "train_loss: 0.04272410646080971\n",
      "train_loss: 0.04385559633374214\n",
      "train_loss: 0.04037376865744591\n",
      "train_loss: 0.045817781239748\n",
      "train_loss: 0.04174108803272247\n",
      "train_loss: 0.0461604967713356\n",
      "train_loss: 0.04378635808825493\n",
      "train_loss: 0.045382533222436905\n",
      "train_loss: 0.040969885885715485\n",
      "train_loss: 0.041642069816589355\n",
      "train_loss: 0.04665917530655861\n",
      "train_loss: 0.04449394717812538\n",
      "train_loss: 0.044573526829481125\n",
      "train_loss: 0.04557755962014198\n",
      "train_loss: 0.04244384914636612\n",
      "train_loss: 0.045949116349220276\n",
      "train_loss: 0.042745042592287064\n",
      "train_loss: 0.043113190680742264\n",
      "train_loss: 0.04385901242494583\n",
      "train_loss: 0.04384063556790352\n",
      "train_loss: 0.04081336781382561\n",
      "train_loss: 0.04421253129839897\n",
      "train_loss: 0.04514896869659424\n",
      "train_loss: 0.04282410070300102\n",
      "train_loss: 0.0440889373421669\n",
      "train_loss: 0.0429484024643898\n",
      "train_loss: 0.037760138511657715\n",
      "train_loss: 0.04384710267186165\n",
      "train_loss: 0.043823789805173874\n",
      "train_loss: 0.036120619624853134\n",
      "train_loss: 0.05134439840912819\n",
      "train_loss: 0.04282425343990326\n",
      "train_loss: 0.0431704968214035\n",
      "train_loss: 0.04798584431409836\n",
      "train_loss: 0.039998918771743774\n",
      "train_loss: 0.04229268059134483\n",
      "train_loss: 0.04529387876391411\n",
      "train_loss: 0.04562189429998398\n",
      "train_loss: 0.050379808992147446\n",
      "train_loss: 0.04617593064904213\n",
      "train_loss: 0.042982734739780426\n",
      "train_loss: 0.042527053505182266\n",
      "train_loss: 0.04497767239809036\n",
      "train_loss: 0.042961373925209045\n",
      "train_loss: 0.04143740236759186\n",
      "train_loss: 0.03825844079256058\n",
      "train_loss: 0.041730742901563644\n",
      "train_loss: 0.0473618321120739\n",
      "train_loss: 0.049156155437231064\n",
      "train_loss: 0.04384195804595947\n",
      "train_loss: 0.04233619570732117\n",
      "train_loss: 0.03969022259116173\n",
      "train_loss: 0.045646633952856064\n",
      "train_loss: 0.04024358466267586\n",
      "train_loss: 0.04065924137830734\n",
      "train_loss: 0.04937418922781944\n",
      "train_loss: 0.04343733936548233\n",
      "train_loss: 0.0424136221408844\n",
      "train_loss: 0.04350541904568672\n",
      "train_loss: 0.04449331760406494\n",
      "train_loss: 0.039446648210287094\n",
      "train_loss: 0.04538486525416374\n",
      "train_loss: 0.039275556802749634\n",
      "train_loss: 0.04624564200639725\n",
      "train_loss: 0.044914014637470245\n",
      "train_loss: 0.046097759157419205\n",
      "train_loss: 0.042822953313589096\n",
      "train_loss: 0.04722593352198601\n",
      "train_loss: 0.04659012705087662\n",
      "train_loss: 0.05152422934770584\n",
      "train_loss: 0.04891612380743027\n",
      "train_loss: 0.04300228878855705\n",
      "train_loss: 0.04286603629589081\n",
      "train_loss: 0.045643653720617294\n",
      "train_loss: 0.045668140053749084\n",
      "train_loss: 0.04884349927306175\n",
      "train_loss: 0.04064423218369484\n",
      "train_loss: 0.04150133207440376\n",
      "train_loss: 0.043537795543670654\n",
      "train_loss: 0.04323958232998848\n",
      "train_loss: 0.03940630704164505\n",
      "train_loss: 0.04069792106747627\n",
      "train_loss: 0.043199505656957626\n",
      "train_loss: 0.04337313771247864\n",
      "train_loss: 0.03966154158115387\n",
      "train_loss: 0.043737124651670456\n",
      "train_loss: 0.04089141637086868\n",
      "train_loss: 0.039730675518512726\n",
      "train_loss: 0.04729697108268738\n",
      "train_loss: 0.04224204272031784\n",
      "train_loss: 0.04616248607635498\n",
      "train_loss: 0.042425550520420074\n",
      "train_loss: 0.043467927724123\n",
      "train_loss: 0.04620765149593353\n",
      "train_loss: 0.05169399455189705\n",
      "train_loss: 0.044124480336904526\n",
      "train_loss: 0.04184691607952118\n",
      "train_loss: 0.04258015751838684\n",
      "train_loss: 0.04258100315928459\n",
      "train_loss: 0.04235493391752243\n",
      "train_loss: 0.0442361906170845\n",
      "train_loss: 0.04441875219345093\n",
      "train_loss: 0.04264194145798683\n",
      "train_loss: 0.044538915157318115\n",
      "train_loss: 0.04864893853664398\n",
      "train_loss: 0.04619966074824333\n",
      "train_loss: 0.04186968877911568\n",
      "train_loss: 0.04519249498844147\n",
      "train_loss: 0.03953596577048302\n",
      "train_loss: 0.04494495689868927\n",
      "train_loss: 0.048175692558288574\n",
      "train_loss: 0.04314092546701431\n",
      "train_loss: 0.047234661877155304\n",
      "train_loss: 0.048630792647600174\n",
      "train_loss: 0.04313512519001961\n",
      "train_loss: 0.04183460772037506\n",
      "train_loss: 0.040403977036476135\n",
      "train_loss: 0.04046610742807388\n",
      "train_loss: 0.04181823879480362\n",
      "train_loss: 0.04383407160639763\n",
      "train_loss: 0.05148385837674141\n",
      "train_loss: 0.04353145509958267\n",
      "train_loss: 0.04944755509495735\n",
      "train_loss: 0.04473123699426651\n",
      "train_loss: 0.045812249183654785\n",
      "train_loss: 0.03988662734627724\n",
      "train_loss: 0.04568246752023697\n",
      "train_loss: 0.04515960067510605\n",
      "train_loss: 0.03978724405169487\n",
      "train_loss: 0.04145687445998192\n",
      "train_loss: 0.04330271854996681\n",
      "train_loss: 0.04625721275806427\n",
      "train_loss: 0.04491472989320755\n",
      "train_loss: 0.04045528173446655\n",
      "train_loss: 0.04505138844251633\n",
      "train_loss: 0.042614854872226715\n",
      "train_loss: 0.041365910321474075\n",
      "train_loss: 0.04023540019989014\n",
      "train_loss: 0.042370714247226715\n",
      "train_loss: 0.04538528993725777\n",
      "train_loss: 0.03638102486729622\n",
      "train_loss: 0.03739023953676224\n",
      "train_loss: 0.043299078941345215\n",
      "train_loss: 0.037448685616254807\n",
      "train_loss: 0.045079443603754044\n",
      "train_loss: 0.04543720930814743\n",
      "train_loss: 0.04127582162618637\n",
      "train_loss: 0.04480195418000221\n",
      "train_loss: 0.03819455951452255\n",
      "train_loss: 0.045464470982551575\n",
      "train_loss: 0.039852824062108994\n",
      "train_loss: 0.04811953380703926\n",
      "train_loss: 0.044818006455898285\n",
      "train_loss: 0.04776646941900253\n",
      "train_loss: 0.045567844063043594\n",
      "train_loss: 0.04556073248386383\n",
      "train_loss: 0.037843070924282074\n",
      "train_loss: 0.04114320129156113\n",
      "train_loss: 0.0449477843940258\n",
      "train_loss: 0.04028283804655075\n",
      "train_loss: 0.04622504115104675\n",
      "train_loss: 0.039961740374565125\n",
      "train_loss: 0.04464529827237129\n",
      "train_loss: 0.040014803409576416\n",
      "train_loss: 0.048175565898418427\n",
      "train_loss: 0.04433800280094147\n",
      "train_loss: 0.04331749305129051\n",
      "train_loss: 0.04150901362299919\n",
      "train_loss: 0.04562189429998398\n",
      "train_loss: 0.042050138115882874\n",
      "train_loss: 0.04405258968472481\n",
      "train_loss: 0.041690416634082794\n",
      "train_loss: 0.04543356969952583\n",
      "train_loss: 0.048954758793115616\n",
      "train_loss: 0.04219946637749672\n",
      "train_loss: 0.039859477430582047\n",
      "train_loss: 0.043133534491062164\n",
      "train_loss: 0.04354409873485565\n",
      "train_loss: 0.041689589619636536\n",
      "train_loss: 0.03858247399330139\n",
      "train_loss: 0.037397731095552444\n",
      "train_loss: 0.042903732508420944\n",
      "train_loss: 0.0373733714222908\n",
      "train_loss: 0.04400922358036041\n",
      "train_loss: 0.04273146763443947\n",
      "train_loss: 0.03839648514986038\n",
      "train_loss: 0.04512561112642288\n",
      "train_loss: 0.04516942426562309\n",
      "train_loss: 0.03762349113821983\n",
      "train_loss: 0.04622526094317436\n",
      "train_loss: 0.04065098613500595\n",
      "train_loss: 0.04682379215955734\n",
      "train_loss: 0.043337080627679825\n",
      "train_loss: 0.04603762924671173\n",
      "train_loss: 0.04164702445268631\n",
      "train_loss: 0.0434451587498188\n",
      "train_loss: 0.04271716997027397\n",
      "train_loss: 0.044000640511512756\n",
      "train_loss: 0.043953850865364075\n",
      "train_loss: 0.04846196249127388\n",
      "train_loss: 0.04597119987010956\n",
      "train_loss: 0.03906363621354103\n",
      "train_loss: 0.04973139613866806\n",
      "train_loss: 0.04736602306365967\n",
      "train_loss: 0.04004748538136482\n",
      "train_loss: 0.04885232448577881\n",
      "train_loss: 0.04168490320444107\n",
      "train_loss: 0.045951008796691895\n",
      "train_loss: 0.04126817360520363\n",
      "train_loss: 0.044719502329826355\n",
      "train_loss: 0.04899848997592926\n",
      "train_loss: 0.045866355299949646\n",
      "train_loss: 0.042692214250564575\n",
      "train_loss: 0.041933346539735794\n",
      "train_loss: 0.04815053194761276\n",
      "train_loss: 0.043670836836099625\n",
      "train_loss: 0.04005233570933342\n",
      "train_loss: 0.038034919649362564\n",
      "train_loss: 0.04012325406074524\n",
      "train_loss: 0.04831833764910698\n",
      "train_loss: 0.03868414834141731\n",
      "train_loss: 0.044641248881816864\n",
      "train_loss: 0.03911535069346428\n",
      "train_loss: 0.04873323440551758\n",
      "train_loss: 0.040690429508686066\n",
      "train_loss: 0.039908457547426224\n",
      "train_loss: 0.043296243995428085\n",
      "train_loss: 0.04190883785486221\n",
      "train_loss: 0.04930320009589195\n",
      "train_loss: 0.0466751903295517\n",
      "train_loss: 0.04155001416802406\n",
      "train_loss: 0.04158128798007965\n",
      "train_loss: 0.042840372771024704\n",
      "train_loss: 0.04028214514255524\n",
      "train_loss: 0.039628542959690094\n",
      "train_loss: 0.04566579684615135\n",
      "train_loss: 0.04727804288268089\n",
      "train_loss: 0.04298117011785507\n",
      "train_loss: 0.042199037969112396\n",
      "train_loss: 0.04019749164581299\n",
      "train_loss: 0.04478490352630615\n",
      "train_loss: 0.04551932215690613\n",
      "train_loss: 0.04088004678487778\n",
      "train_loss: 0.04704666882753372\n",
      "train_loss: 0.044073741883039474\n",
      "train_loss: 0.04601071774959564\n",
      "train_loss: 0.04989928379654884\n",
      "train_loss: 0.04430004954338074\n",
      "train_loss: 0.04346973076462746\n",
      "train_loss: 0.04551718011498451\n",
      "train_loss: 0.0423254631459713\n",
      "train_loss: 0.042566679418087006\n",
      "train_loss: 0.046807628124952316\n",
      "train_loss: 0.04452615603804588\n",
      "train_loss: 0.04556635394692421\n",
      "train_loss: 0.044914741069078445\n",
      "train_loss: 0.041263092309236526\n",
      "train_loss: 0.04565431550145149\n",
      "train_loss: 0.04329875111579895\n",
      "train_loss: 0.03868292272090912\n",
      "train_loss: 0.04231123998761177\n",
      "train_loss: 0.044580861926078796\n",
      "train_loss: 0.04233168065547943\n",
      "train_loss: 0.04374607279896736\n",
      "train_loss: 0.03832211345434189\n",
      "train_loss: 0.04217460751533508\n",
      "train_loss: 0.04267381876707077\n",
      "train_loss: 0.04571913555264473\n",
      "train_loss: 0.039453037083148956\n",
      "train_loss: 0.036795906722545624\n",
      "train_loss: 0.04035254940390587\n",
      "train_loss: 0.045845285058021545\n",
      "train_loss: 0.04544534534215927\n",
      "train_loss: 0.04568200185894966\n",
      "train_loss: 0.047443896532058716\n",
      "train_loss: 0.04072007164359093\n",
      "train_loss: 0.04197906702756882\n",
      "train_loss: 0.03658484295010567\n",
      "train_loss: 0.044790416955947876\n",
      "train_loss: 0.04154863953590393\n",
      "train_loss: 0.04376310110092163\n",
      "train_loss: 0.04233347624540329\n",
      "train_loss: 0.038864616304636\n",
      "train_loss: 0.045352812856435776\n",
      "train_loss: 0.041232652962207794\n",
      "train_loss: 0.04252049699425697\n",
      "train_loss: 0.04302583634853363\n",
      "train_loss: 0.04387504234910011\n",
      "train_loss: 0.04236863553524017\n",
      "train_loss: 0.044742126017808914\n",
      "train_loss: 0.04331878572702408\n",
      "train_loss: 0.04388858750462532\n",
      "train_loss: 0.04271089658141136\n",
      "train_loss: 0.03836260735988617\n",
      "train_loss: 0.042543940246105194\n",
      "train_loss: 0.04700985550880432\n",
      "train_loss: 0.045749664306640625\n",
      "train_loss: 0.04234800487756729\n",
      "train_loss: 0.042816463857889175\n",
      "train_loss: 0.045273493975400925\n",
      "train_loss: 0.04827839881181717\n",
      "train_loss: 0.04318312183022499\n",
      "train_loss: 0.04612431302666664\n",
      "train_loss: 0.041700344532728195\n",
      "train_loss: 0.037890370935201645\n",
      "train_loss: 0.04610123857855797\n",
      "train_loss: 0.044301051646471024\n",
      "train_loss: 0.046591922640800476\n",
      "train_loss: 0.04420170560479164\n",
      "train_loss: 0.04977790266275406\n",
      "train_loss: 0.04291224852204323\n",
      "train_loss: 0.0485055111348629\n",
      "train_loss: 0.03938161954283714\n",
      "train_loss: 0.04311773553490639\n",
      "train_loss: 0.040339913219213486\n",
      "train_loss: 0.045580338686704636\n",
      "train_loss: 0.041619446128606796\n",
      "train_loss: 0.04327476769685745\n",
      "train_loss: 0.0408797450363636\n",
      "train_loss: 0.04103834554553032\n",
      "train_loss: 0.04101970046758652\n",
      "train_loss: 0.042069919407367706\n",
      "train_loss: 0.03838001564145088\n",
      "train_loss: 0.04174961894750595\n",
      "train_loss: 0.04586181789636612\n",
      "train_loss: 0.04338638484477997\n",
      "train_loss: 0.045726511627435684\n",
      "train_loss: 0.04001178964972496\n",
      "train_loss: 0.0350361242890358\n",
      "train_loss: 0.04412643983960152\n",
      "train_loss: 0.04232814162969589\n",
      "train_loss: 0.0473344512283802\n",
      "train_loss: 0.04390167444944382\n",
      "train_loss: 0.04286152869462967\n",
      "train_loss: 0.042922280728816986\n",
      "train_loss: 0.04200085625052452\n",
      "train_loss: 0.04809264466166496\n",
      "train_loss: 0.043725382536649704\n",
      "train_loss: 0.039268478751182556\n",
      "train_loss: 0.040915798395872116\n",
      "train_loss: 0.04414049908518791\n",
      "train_loss: 0.03909459337592125\n",
      "train_loss: 0.041937485337257385\n",
      "train_loss: 0.04736814647912979\n",
      "train_loss: 0.041184842586517334\n",
      "train_loss: 0.041366156190633774\n",
      "train_loss: 0.04360028728842735\n",
      "train_loss: 0.04809168726205826\n",
      "train_loss: 0.04421825706958771\n",
      "train_loss: 0.04187700152397156\n",
      "train_loss: 0.040332164615392685\n",
      "train_loss: 0.03801937773823738\n",
      "train_loss: 0.0428902767598629\n",
      "train_loss: 0.036284707486629486\n",
      "train_loss: 0.03677791729569435\n",
      "train_loss: 0.03629082068800926\n",
      "train_loss: 0.04448997601866722\n",
      "train_loss: 0.043757934123277664\n",
      "train_loss: 0.03990793973207474\n",
      "train_loss: 0.04337708652019501\n",
      "train_loss: 0.04308157414197922\n",
      "train_loss: 0.037217602133750916\n",
      "train_loss: 0.04242277145385742\n",
      "train_loss: 0.04054875671863556\n",
      "train_loss: 0.04293810576200485\n",
      "train_loss: 0.04397019371390343\n",
      "train_loss: 0.042154181748628616\n",
      "train_loss: 0.04162006080150604\n",
      "train_loss: 0.04635048657655716\n",
      "train_loss: 0.041063617914915085\n",
      "train_loss: 0.04892122372984886\n",
      "train_loss: 0.046940404921770096\n",
      "train_loss: 0.04780825600028038\n",
      "train_loss: 0.04411107674241066\n",
      "train_loss: 0.042851563543081284\n",
      "train_loss: 0.046348024159669876\n",
      "train_loss: 0.03979601711034775\n",
      "train_loss: 0.04533485323190689\n",
      "train_loss: 0.042069464921951294\n",
      "train_loss: 0.039637379348278046\n",
      "train_loss: 0.04250919818878174\n",
      "train_loss: 0.04355572536587715\n",
      "train_loss: 0.041357748210430145\n",
      "train_loss: 0.04885362461209297\n",
      "train_loss: 0.0398038774728775\n",
      "train_loss: 0.04416072368621826\n",
      "train_loss: 0.046335190534591675\n",
      "train_loss: 0.044183287769556046\n",
      "train_loss: 0.03933753818273544\n",
      "train_loss: 0.04478615149855614\n",
      "train_loss: 0.04412619024515152\n",
      "train_loss: 0.042295701801776886\n",
      "train_loss: 0.04033248499035835\n",
      "train_loss: 0.04445650056004524\n",
      "train_loss: 0.04116338491439819\n",
      "train_loss: 0.04442945122718811\n",
      "train_loss: 0.041999347507953644\n",
      "train_loss: 0.04694366827607155\n",
      "train_loss: 0.04093700274825096\n",
      "train_loss: 0.045698896050453186\n",
      "train_loss: 0.04107717424631119\n",
      "train_loss: 0.04509762302041054\n",
      "train_loss: 0.04471128061413765\n",
      "train_loss: 0.03970177844166756\n",
      "train_loss: 0.042791180312633514\n",
      "train_loss: 0.04339970275759697\n",
      "train_loss: 0.040844861418008804\n",
      "train_loss: 0.03714337572455406\n",
      "train_loss: 0.04611775279045105\n",
      "train_loss: 0.04392606392502785\n",
      "train_loss: 0.04104463756084442\n",
      "train_loss: 0.040402933955192566\n",
      "train_loss: 0.044161707162857056\n",
      "train_loss: 0.040616441518068314\n",
      "train_loss: 0.04396038129925728\n",
      "train_loss: 0.04215351864695549\n",
      "train_loss: 0.039757512509822845\n",
      "train_loss: 0.040572572499513626\n",
      "train_loss: 0.05004880949854851\n",
      "train_loss: 0.041095439344644547\n",
      "train_loss: 0.04333045333623886\n",
      "train_loss: 0.04439703747630119\n",
      "train_loss: 0.043354637920856476\n",
      "train_loss: 0.04112378880381584\n",
      "train_loss: 0.04666586220264435\n",
      "train_loss: 0.04480530321598053\n",
      "train_loss: 0.03600916638970375\n",
      "train_loss: 0.041590310633182526\n",
      "train_loss: 0.047959666699171066\n",
      "train_loss: 0.04682312160730362\n",
      "train_loss: 0.0466001071035862\n",
      "train_loss: 0.038024142384529114\n",
      "train_loss: 0.04323568195104599\n",
      "train_loss: 0.04424303397536278\n",
      "train_loss: 0.04278681054711342\n",
      "train_loss: 0.04574184864759445\n",
      "train_loss: 0.045528341084718704\n",
      "train_loss: 0.04445881024003029\n",
      "train_loss: 0.04414644092321396\n",
      "train_loss: 0.040534693747758865\n",
      "train_loss: 0.03737767040729523\n",
      "train_loss: 0.040856048464775085\n",
      "train_loss: 0.04698104038834572\n",
      "train_loss: 0.041783656924963\n",
      "train_loss: 0.039786871522665024\n",
      "train_loss: 0.03843807056546211\n",
      "train_loss: 0.04358835518360138\n",
      "train_loss: 0.04055808112025261\n",
      "train_loss: 0.040241193026304245\n",
      "train_loss: 0.034943390637636185\n",
      "train_loss: 0.03934280574321747\n",
      "train_loss: 0.0470707081258297\n",
      "train_loss: 0.042232170701026917\n",
      "train_loss: 0.03792892396450043\n",
      "train_loss: 0.041279394179582596\n",
      "train_loss: 0.045700374990701675\n",
      "train_loss: 0.04169187694787979\n",
      "train_loss: 0.04582255706191063\n",
      "train_loss: 0.05029945448040962\n",
      "train_loss: 0.043000441044569016\n",
      "train_loss: 0.038961559534072876\n",
      "train_loss: 0.03722790628671646\n",
      "train_loss: 0.044828396290540695\n",
      "train_loss: 0.044785674661397934\n",
      "train_loss: 0.03738037496805191\n",
      "train_loss: 0.04525385797023773\n",
      "train_loss: 0.04493071138858795\n",
      "train_loss: 0.04329169541597366\n",
      "train_loss: 0.04809803143143654\n",
      "train_loss: 0.0410148985683918\n",
      "train_loss: 0.04276348650455475\n",
      "train_loss: 0.03507872670888901\n",
      "train_loss: 0.04393618926405907\n",
      "train_loss: 0.04300636053085327\n",
      "train_loss: 0.03839391469955444\n",
      "train_loss: 0.04464251548051834\n",
      "train_loss: 0.04362623393535614\n",
      "train_loss: 0.049407292157411575\n",
      "train_loss: 0.043739788234233856\n",
      "train_loss: 0.04418811947107315\n",
      "train_loss: 0.04164357855916023\n",
      "train_loss: 0.042496610432863235\n",
      "train_loss: 0.044147998094558716\n",
      "train_loss: 0.045106906443834305\n",
      "train_loss: 0.04585705325007439\n",
      "train_loss: 0.03969131410121918\n",
      "train_loss: 0.04045524820685387\n",
      "train_loss: 0.04294842109084129\n",
      "train_loss: 0.04202307388186455\n",
      "train_loss: 0.04521337151527405\n",
      "train_loss: 0.04733031615614891\n",
      "train_loss: 0.04059484973549843\n",
      "train_loss: 0.0368521511554718\n",
      "train_loss: 0.047201815992593765\n",
      "train_loss: 0.0444331169128418\n",
      "train_loss: 0.04601248726248741\n",
      "train_loss: 0.04632042720913887\n",
      "train_loss: 0.044094886630773544\n",
      "train_loss: 0.04168812930583954\n",
      "train_loss: 0.039877068251371384\n",
      "train_loss: 0.042717523872852325\n",
      "train_loss: 0.045811545103788376\n",
      "train_loss: 0.04523825645446777\n",
      "train_loss: 0.049261316657066345\n",
      "train_loss: 0.04244022071361542\n",
      "train_loss: 0.04727385938167572\n",
      "train_loss: 0.041709430515766144\n",
      "train_loss: 0.041404880583286285\n",
      "train_loss: 0.04297681525349617\n",
      "train_loss: 0.04154070094227791\n",
      "train_loss: 0.03994254022836685\n",
      "train_loss: 0.04333162307739258\n",
      "train_loss: 0.040023986250162125\n",
      "train_loss: 0.04567740485072136\n",
      "train_loss: 0.03981863707304001\n",
      "train_loss: 0.04675636440515518\n",
      "train_loss: 0.04055376723408699\n",
      "train_loss: 0.03837164118885994\n",
      "train_loss: 0.04432147741317749\n",
      "train_loss: 0.04273417592048645\n",
      "train_loss: 0.04477611929178238\n",
      "train_loss: 0.040839485824108124\n",
      "train_loss: 0.04072786122560501\n",
      "train_loss: 0.051398519426584244\n",
      "train_loss: 0.039301797747612\n",
      "train_loss: 0.039235297590494156\n",
      "train_loss: 0.041707854717969894\n",
      "train_loss: 0.039934661239385605\n",
      "train_loss: 0.039070986211299896\n",
      "train_loss: 0.04598073661327362\n",
      "train_loss: 0.046586424112319946\n",
      "train_loss: 0.04568643867969513\n",
      "train_loss: 0.0473417267203331\n",
      "train_loss: 0.03886675834655762\n",
      "train_loss: 0.04248878359794617\n",
      "train_loss: 0.04607934132218361\n",
      "train_loss: 0.042105868458747864\n",
      "train_loss: 0.04599789157509804\n",
      "train_loss: 0.04566846415400505\n",
      "train_loss: 0.04065478593111038\n",
      "train_loss: 0.04057953879237175\n",
      "train_loss: 0.04345215857028961\n",
      "train_loss: 0.04372946172952652\n",
      "train_loss: 0.04041580483317375\n",
      "train_loss: 0.041633881628513336\n",
      "train_loss: 0.040104128420352936\n",
      "train_loss: 0.04180131480097771\n",
      "train_loss: 0.04819360002875328\n",
      "train_loss: 0.04295891895890236\n",
      "train_loss: 0.0418691448867321\n",
      "train_loss: 0.04523835703730583\n",
      "train_loss: 0.04068019241094589\n",
      "train_loss: 0.045503828674554825\n",
      "train_loss: 0.04115476831793785\n",
      "train_loss: 0.046120379120111465\n",
      "train_loss: 0.047685276716947556\n",
      "train_loss: 0.05276218056678772\n",
      "train_loss: 0.04182994365692139\n",
      "train_loss: 0.041233133524656296\n",
      "train_loss: 0.04264882206916809\n",
      "train_loss: 0.04446311295032501\n",
      "train_loss: 0.0432669073343277\n",
      "train_loss: 0.036590564996004105\n",
      "train_loss: 0.04107237607240677\n",
      "train_loss: 0.04097728431224823\n",
      "train_loss: 0.04418017715215683\n",
      "train_loss: 0.043381329625844955\n",
      "train_loss: 0.04094798117876053\n",
      "train_loss: 0.04272898659110069\n",
      "train_loss: 0.03940948471426964\n",
      "train_loss: 0.040967296808958054\n",
      "train_loss: 0.04306650906801224\n",
      "train_loss: 0.046762559562921524\n",
      "train_loss: 0.04334258288145065\n",
      "train_loss: 0.04610203579068184\n",
      "train_loss: 0.043245721608400345\n",
      "train_loss: 0.04648781195282936\n",
      "train_loss: 0.03926396742463112\n",
      "train_loss: 0.04130764305591583\n",
      "train_loss: 0.047113943845033646\n",
      "train_loss: 0.03884300962090492\n",
      "train_loss: 0.0450969897210598\n",
      "train_loss: 0.0430704765021801\n",
      "train_loss: 0.04239682853221893\n",
      "train_loss: 0.04256371036171913\n",
      "train_loss: 0.043684713542461395\n",
      "train_loss: 0.04072334244847298\n",
      "train_loss: 0.04100162163376808\n",
      "train_loss: 0.03851531818509102\n",
      "train_loss: 0.04037376865744591\n",
      "train_loss: 0.044700801372528076\n",
      "train_loss: 0.041363976895809174\n",
      "train_loss: 0.0398763008415699\n",
      "train_loss: 0.04383157938718796\n",
      "train_loss: 0.04142621159553528\n",
      "train_loss: 0.04624149203300476\n",
      "train_loss: 0.04464907944202423\n",
      "train_loss: 0.048495784401893616\n",
      "train_loss: 0.04336614906787872\n",
      "train_loss: 0.04747861623764038\n",
      "train_loss: 0.04283490404486656\n",
      "train_loss: 0.04067838937044144\n",
      "train_loss: 0.0365682877600193\n",
      "train_loss: 0.04223555698990822\n",
      "train_loss: 0.04390342906117439\n",
      "train_loss: 0.04280361905694008\n",
      "train_loss: 0.04675990715622902\n",
      "train_loss: 0.04605470225214958\n",
      "train_loss: 0.04125422611832619\n",
      "train_loss: 0.04041894152760506\n",
      "train_loss: 0.04264087975025177\n",
      "train_loss: 0.03403960540890694\n",
      "train_loss: 0.04060201719403267\n",
      "train_loss: 0.034927673637866974\n",
      "train_loss: 0.04047667980194092\n",
      "train_loss: 0.0424124114215374\n",
      "train_loss: 0.04314647242426872\n",
      "train_loss: 0.03982650488615036\n",
      "train_loss: 0.04151284322142601\n",
      "train_loss: 0.03916575014591217\n",
      "train_loss: 0.04460136592388153\n",
      "train_loss: 0.04647446423768997\n",
      "train_loss: 0.04142344743013382\n",
      "train_loss: 0.04416621848940849\n",
      "train_loss: 0.04869117587804794\n",
      "train_loss: 0.041136860847473145\n",
      "train_loss: 0.04642112925648689\n",
      "train_loss: 0.04382691532373428\n",
      "train_loss: 0.03483825549483299\n",
      "train_loss: 0.042242709547281265\n",
      "train_loss: 0.04622188210487366\n",
      "train_loss: 0.042603909969329834\n",
      "train_loss: 0.03917866572737694\n",
      "train_loss: 0.04075159877538681\n",
      "train_loss: 0.03996759280562401\n",
      "train_loss: 0.045010458678007126\n",
      "train_loss: 0.042730871587991714\n",
      "train_loss: 0.03850497305393219\n",
      "train_loss: 0.053446102887392044\n",
      "train_loss: 0.04132543131709099\n",
      "train_loss: 0.04183429479598999\n",
      "train_loss: 0.03480960801243782\n",
      "train_loss: 0.03889898955821991\n",
      "train_loss: 0.04251987114548683\n",
      "train_loss: 0.03976716101169586\n",
      "train_loss: 0.03974456712603569\n",
      "train_loss: 0.04062294214963913\n",
      "train_loss: 0.03946815803647041\n",
      "train_loss: 0.03910268098115921\n",
      "train_loss: 0.036067694425582886\n",
      "train_loss: 0.04385580122470856\n",
      "train_loss: 0.04705450311303139\n",
      "train_loss: 0.042299795895814896\n",
      "train_loss: 0.03950256109237671\n",
      "train_loss: 0.03921408951282501\n",
      "train_loss: 0.045534294098615646\n",
      "train_loss: 0.04304241016507149\n",
      "train_loss: 0.04369843751192093\n",
      "train_loss: 0.041797198355197906\n",
      "train_loss: 0.0431654192507267\n",
      "train_loss: 0.03849368542432785\n",
      "train_loss: 0.041494350880384445\n",
      "train_loss: 0.03819732740521431\n",
      "train_loss: 0.04466548189520836\n",
      "train_loss: 0.04356089234352112\n",
      "train_loss: 0.04151339456439018\n",
      "train_loss: 0.03912908956408501\n",
      "train_loss: 0.03462253883481026\n",
      "train_loss: 0.04133471101522446\n",
      "train_loss: 0.041691191494464874\n",
      "train_loss: 0.03720968961715698\n",
      "train_loss: 0.04227902740240097\n",
      "train_loss: 0.04319557920098305\n",
      "train_loss: 0.043962836265563965\n",
      "train_loss: 0.041526637971401215\n",
      "train_loss: 0.04032173752784729\n",
      "train_loss: 0.03950664773583412\n",
      "train_loss: 0.04250102490186691\n",
      "train_loss: 0.04102974757552147\n",
      "train_loss: 0.050182633101940155\n",
      "train_loss: 0.04149294272065163\n",
      "train_loss: 0.04833138734102249\n",
      "train_loss: 0.04437778517603874\n",
      "train_loss: 0.046287789940834045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_loss: 0.042352091521024704\n",
      "train_loss: 0.04379018396139145\n",
      "train_loss: 0.04103630408644676\n",
      "train_loss: 0.041470468044281006\n",
      "train_loss: 0.040585920214653015\n",
      "train_loss: 0.0384526252746582\n",
      "train_loss: 0.03974176198244095\n",
      "train_loss: 0.03917107358574867\n",
      "train_loss: 0.04524951055645943\n",
      "train_loss: 0.04062916338443756\n",
      "train_loss: 0.043837886303663254\n",
      "train_loss: 0.044590551406145096\n",
      "train_loss: 0.04531894251704216\n",
      "train_loss: 0.042006928473711014\n",
      "train_loss: 0.03977338224649429\n",
      "train_loss: 0.04366181790828705\n",
      "train_loss: 0.047427307814359665\n",
      "train_loss: 0.046864818781614304\n",
      "train_loss: 0.04250354692339897\n",
      "train_loss: 0.039451614022254944\n",
      "train_loss: 0.047011759132146835\n"
     ]
    }
   ],
   "source": [
    "# data\n",
    "dataset = MNIST(root='./data', download=True, transform=ToTensor())\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# trainer\n",
    "trainer = pl.Trainer(max_epochs=1)\n",
    "trainer.fit(model=ae, train_dataloaders=train_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
